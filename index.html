<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>LiuYongQian</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="永远相信美好的事情将要发生！">
<meta property="og:type" content="website">
<meta property="og:title" content="LiuYongQian">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="LiuYongQian">
<meta property="og:description" content="永远相信美好的事情将要发生！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LiuYongQian">
<meta name="twitter:description" content="永远相信美好的事情将要发生！">
  
    <link rel="alternate" href="/atom.xml" title="LiuYongQian" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiuYongQian</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">永远相信美好的事情将要发生！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-scrapy基础了解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/29/scrapy基础了解/" class="article-date">
  <time datetime="2018-03-29T01:25:36.000Z" itemprop="datePublished">2018-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/29/scrapy基础了解/">scrapy基础了解</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy基础了解</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中</li>
<li>依赖包<ul>
<li>1.wheel      安装该文件后就可以安装.whl的依赖文件</li>
<li>2.lxml       解析页面 </li>
<li>3.PyOpenssl</li>
<li>4.Twisted</li>
<li>5.Pywin32，pypiwin32</li>
<li>6.Scrapy </li>
</ul>
</li>
<li>基本思路:<img src="../scrapy.jpg" alt="Scrapy基本思路"><ul>
<li>1.Scrapy Engine: 引擎，负责Spiders、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等等！</li>
<li>2.Scheduler(调度器): 它负责接受引擎发送过来的requests请求，并按照一定的方式进行整理排列，入队、并等待Scrapy Engine(引擎)来请求时，交给引擎</li>
<li>3.Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spiders来处理</li>
<li>4.Spiders：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)</li>
<li>5.Item Pipeline：它负责处理Spiders中获取到的Item，并进行处理，比如去重，持久化存储（存数据库，写入文件，总之就是保存数据用的）</li>
</ul>
</li>
<li>测试网站：<a href="http://quotes.toscrape.com/" target="_blank" rel="noopener">http://quotes.toscrape.com/</a></li>
</ul>
<p></p><h6>详解</h6><p></p>
<ul>
<li><p>1.进入要放置项目的目录，shift+右键的shell，输入命令：<code>scrapy startproject quotetutorial</code>，创建项目</p>
<ul>
<li>spiders    #这个目录放置爬虫</li>
<li>items.py   #这个文件定义我们需要获取的字段</li>
<li>pipelines.py    #这个文件用来定义数据存储</li>
<li>settings.py        #这个文件用来设置</li>
</ul>
</li>
<li><p>2.进入项目，<code>cd quotetutorial</code>,创建爬虫：<code>scrapy genspider quotes quotes.toscrape.com</code> </p>
</li>
<li><p>3.在spiders文件夹下的quotes中编写自己的爬虫</p>
<pre><code>import scrapy
from quotetutorial.items import QuoteItem
class QuotesSpider(scrapy.Spider):
    name = &apos;quotes&apos;
    allowed_domains = [&apos;quotes.toscrape.com&apos;]
    start_urls = [&apos;http://quotes.toscrape.com/&apos;]

    def parse(self, response):
        quotes=response.css(&apos;.quote&apos;)
        for quote in quotes:
            item=QuoteItem() #先声明一个对象，然后赋值
            text=quote.css(&apos;.text::text&apos;).extract_first()
            author=quote.css(&apos;.author::text&apos;).extract_first()
            tags=quote.css(&apos;.tags .tag::text&apos;).extract()
            item[&apos;text&apos;]=text
            item[&apos;author&apos;]=author
            item[&apos;tags&apos;]=tags
            yield item #做下一步的存储操作
        next=response.css(&apos;.pager .next a::attr(href)&apos;).extract_first()
        url=response.urljoin(next)
        yield scrapy.Request(url=url,callback=self.parse)
</code></pre></li>
<li><p>4.在items.py文件中定义一些字段，这些字段用来临时存储需要保存的数据。方便后面保存数据到其他地方，比如数据库或者本地文本之类的</p>
<pre><code>import scrapy
class QuoteItem(scrapy.Item):
    text=scrapy.Field()
    author=scrapy.Field()
    tags=scrapy.Field()
</code></pre></li>
<li><p>5.在Terminal中运行爬虫<code>scrapy crawl quotes</code>;运行并且保存爬取数据为json格式<code>scrapy crawl quotes -o quotes.json</code> </p>
</li>
<li><p>6.保存数据到Mongodb中</p>
<ul>
<li><p>6.1在pipelines.py编写连接</p>
<pre><code>from scrapy.exceptions import DropItem
import pymongo
class TextPipeline(object):
    def __init__(self):
        self.limit=50
    def process_item(self, item, spider):
        if item[&apos;text&apos;]:
            if len(item[&apos;text&apos;])&gt;self.limit:
                item[&apos;text&apos;]=item[&apos;text&apos;][0:self.limit].rstrip()+&apos;...&apos;
            return item
        else:
            return DropItem(&apos;Missing Text&apos;)   #如果text不存在，则抛出异常
class MongoPipeline(object):
    def __init__(self,mongo_uri,mongo_db):
        self.mongo_uri=mongo_uri
        self.mongo_db=mongo_db
    @classmethod
    def from_crawler(cls,crawler):
        return cls(
            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),
            mongo_db=crawler.settings.get(&apos;MONGO_DB&apos;)
        )
    def open_spider(self,spider):
        self.client=pymongo.MongoClient(self.mongo_uri)
        self.db=self.client[self.mongo_db]
    def process_item(self,item,spider):
        name=item.__class__.__name__
        self.db[name].insert(dict(item))
        return item
    def close_spider(self,spider):
        self.client.close()  
</code></pre></li>
<li><p>6.2在settings中设置</p>
<pre><code>MONGO_URI=&apos;localhost:27017&apos;
MONGO_DB=&apos;quotetutorial&apos;

ITEM_PIPELINES = {
   &apos;quotetutorial.pipelines.TextPipeline&apos;: 300,
   &apos;quotetutorial.pipelines.MongoPipeline&apos;: 1000,
}
</code></pre></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/29/scrapy基础了解/" data-id="cjffk8zy50031awwvxkj9v5xh" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-网络配置、系统查看" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/网络配置、系统查看/" class="article-date">
  <time datetime="2018-03-28T15:00:41.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/网络配置、系统查看/">网络配置、系统查看</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>网络配置、系统查看</h5><p></p>
<hr>
<hr>
<p></p><h6>网络配置</h6><p></p>
<ul>
<li>VMware的三种网络连接方式区别</li>
<li>桥接模式<ul>
<li>在局域网内，虚拟机和宿主机视为两台PC机；可以单独通过局域网网关或者路由访问外网</li>
<li>利用相同的网关网段配置，Bridged可用来配置集群</li>
</ul>
</li>
<li>NAT（网络地址转换）<ul>
<li>NAT方式使虚拟机接入外网方便，不需要进行其他配置，只需要物理主机可以上网即可</li>
<li>NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，无法进行手工修改，因此虚拟系统也就无法和本局域网中的其他真实主机进行通讯</li>
<li>不能用NAT配置集群</li>
</ul>
</li>
<li>Host-Only（主机）<ul>
<li>这种模式下，所有局域网内所有虚拟机互通，但虚拟机无法访问外网，与外网完全隔离</li>
<li>此种模式同样可以配置集群，但是集群无法访问外网，比较适合公司内网</li>
</ul>
</li>
</ul>
<p></p><h6>linux系统ifconfig命令不显示IP地址或者只显示127.0.0.1</h6><p></p>
<ul>
<li>1.在Linux系统中输入命令:   vi  /etc/sysconfig/network-scripts/ifcfg-ens33</li>
<li>2.修改文件中的ONBOOT=no,将no改为yes</li>
<li>3.重启服务: service network restart</li>
</ul>
<p></p><h6>系统查看</h6><p></p>
<ul>
<li><p>查看进程</p>
<pre><code>ps -A 显示所有程序
ps -H 显示树状结构，表示程序间的相互关系
ps u 以用户为主的格式来显示程序状况
ps aux|less 查看所有运行中的进程
</code></pre></li>
<li><p>监控系统资源</p>
<pre><code>top 查看整个系统运行状况；该命令功能十分强大，但是它的缺点是会消耗很多系统资源
free -m 显示内存使用情况
</code></pre></li>
<li><p>查看硬盘占用</p>
<pre><code>df -h  检查linux服务器的文件系统的磁盘空间占用情况
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/网络配置、系统查看/" data-id="cjffk9015004kawwv5gzl4e5p" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-vi-vim" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/vi-vim/" class="article-date">
  <time datetime="2018-03-28T14:55:30.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/vi-vim/">vi/vim</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>vi/vim</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>vi是一款用来创建编辑文件的文本编辑软件</li>
<li>vi的三大模式：<ul>
<li>命令模式：用户刚刚启动 vi，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符</li>
<li>底线命令模式：在命令模式下按下:（英文冒号）就进入了底线命令模式，主要进行文件的保存和退出</li>
<li>编辑模式：在命令模式下按下i就进入了编辑模式</li>
</ul>
</li>
<li>模式之间的转化常用到Esc，Shift+：</li>
</ul>
<p></p><h6>命令模式</h6><p></p>
<ul>
<li><p>常用命令</p>
<pre><code>i 切换到编辑模式，以输入字符；在当前光标处插入
a 在当前光标处下一个字符插入
o 在当前光标处下一行插入新的一行
</code></pre></li>
</ul>
<p></p><h6>底线命令行模式</h6><p></p>
<ul>
<li><p>常用命令</p>
<pre><code>:q       #表示不保存退出
:q!         #强制退出
:w         #保存修改内容
:wq         #保存并退出
:set nu  #显示行号
:set nonu   #不显示行号
:r 文件名    #在编辑的数据中，读入另一个档案的数据，将文件内容加到游标所在行后面
:1,$s /word1/word2/g  #从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 
:n1,n2s/word1/word2/g #n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2
</code></pre></li>
</ul>
<p></p><h6>编辑模式</h6><p></p>
<ul>
<li><p>删除、复制、粘贴</p>
<pre><code>gg  移到这个文件的第一行
G   移到这个文件的最后一行
ngg 移到这个文件的第几行

yy     复制光标所在行
nyy 复制光标所在的向下n行

P  大写，粘贴在光标的上一行
p  小写，粘贴在光标的下一行

dd        删除光标所在一整行
ndd        删除光标所在向下n行

数字0    移到这一行的最前面
$         移到这一行的最后面

u        撤销上一次的操作
Ctrl+r    恢复撤销
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/vi-vim/" data-id="cjffk8zyo003aawwvhqz3ft3x" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-linux常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/linux常用命令/" class="article-date">
  <time datetime="2018-03-28T09:05:54.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/linux常用命令/">linux常用命令</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>linux常用命令</h5><p></p>
<hr>
<hr>
<p></p><h6>常见的系统目录结构</h6><p></p>
<ul>
<li><p>根目录下</p>
<pre><code>[root@localhost ~]# ls /
bin   dev  ftp   lib    media  opt   root  sbin  sys  usr
boot  etc  home  lib64  mnt    proc  run   srv   tmp  var
</code></pre><ul>
<li>bin：Binary的缩写, 这个目录存放着最经常使用的命令</li>
<li>boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件</li>
<li>dev：Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的</li>
<li>etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录</li>
<li>home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的</li>
<li>lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库</li>
<li>media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下</li>
<li>mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了</li>
<li>opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的</li>
<li>proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息</li>
<li>root：该目录为系统管理员，也称作超级权限者的用户主目录</li>
<li>tmp：这个目录是用来存放一些临时文件的</li>
<li>usr：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录</li>
<li>var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件</li>
</ul>
</li>
</ul>
<p></p><h6>终端</h6><p></p>
<ul>
<li><p>用户</p>
<pre><code>新建用户：useradd &lt;name&gt;
         passwd &lt;pwd&gt;
删除用户：userdel &lt;name&gt;
切换用户：su - &lt;name&gt;
退出当前用户：logout (普通用户)
             exit  （管理用户）
</code></pre></li>
<li><p>前缀</p>
<pre><code>[root@localhost ~]# 

1.root 表示登录的用户名
2.localhost 表示登录的主机
3.~ 表示当前用户的所在路径，即/root
4.# 表示超管用户，$ 表示普通用户
</code></pre></li>
<li><p>开机关机<br>不管是重启系统还是关闭系统，首先要运行sync命令，把内存中的数据写到磁盘中</p>
<pre><code>sync 将数据由内存同步到硬盘中
shutdown -h now 离开关机
shutdown -h +10 10分钟后关机
shutdown -h 10:10 系统会在今天的10:10关机
reboot 系统重启
halt 关闭系统
</code></pre></li>
</ul>
<p></p><h6>目录/文件命令</h6><p></p>
<ul>
<li><p>新建目录</p>
<pre><code>mkdir &lt;目录名&gt;                        创建单个目录
mkdir -p &lt;目录名1&gt;/&lt;目录名2&gt;/&lt;目录名3&gt; 创建多层目录
mkdir -m *** &lt;目录名&gt;                 创建目录时指定权限，三颗星代表rwx的数字码
</code></pre></li>
<li><p>新建文件</p>
<pre><code>touch 文件名
</code></pre></li>
<li><p>删除目录</p>
<pre><code>rmdir &lt;目录名&gt;        删除空的目录
rm -r &lt;目录名&gt;        递归删除整个目录树,非空
rm &lt;文件名或者目录名&gt;        删除文件
rm -i &lt;文件名或者目录名&gt;     互动模式，在删除前会询问是否动作
rm -f &lt;文件名&gt;        强制删除文件，没有提示
</code></pre></li>
<li><p>查看目录</p>
<pre><code>ls 表示查看当前目录下的文件或者文件夹
ls -a 表示查看当前目录下的所有内容，包括隐藏文件
ls -l 表示查看当前目录下内容的详细信息
ls -al 表示查看当前目录下所有内容的详细内容
</code></pre></li>
<li><p>切换目录</p>
<pre><code>cd [相对路径或绝对路径] .表示当前路径  ..表示上层路径
</code></pre></li>
<li><p>复制目录/文件</p>
<pre><code>cp 源文件 /目的地址
cp -i 源文件 /目的地址     若目标档已存在，在覆盖时会先询问动作的进行
</code></pre></li>
<li><p>剪切目录/文件</p>
<pre><code>mv 文件名/目录名 目的地
</code></pre></li>
<li><p>重命名</p>
<pre><code>mv 文件名/目录名 新的文件名/目录名
</code></pre></li>
</ul>
<p></p><h6>文件内容查看</h6><p></p>
<ul>
<li><p>cat、more、head</p>
<pre><code>cat 文件名      #正序查看，由第一行开始显示文件内容
cat -n 文件名   #连同空白行也会显示行号

tac 文件名      #倒序查看
tac -n 文件名   #连同空白行也会显示行号

more 文件名     #查看大文件，显示百分比；空白键代表向下翻页，Enter键表示向下翻行
less 文件夹     #查看大文件，不显示百分比；空白键代表向下翻页，[pgup][pgdn]代表向上向下翻页

head 文件名             #默认显示前10行
head -n 数字 文件名       #规定显示前几行

tail 文件名               #默认显示最后10行
tail -n 数字 文件名      #规定显示最后几行
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/linux常用命令/" data-id="cjffk8zx2002fawwvqvdichfs" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-session会话" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/session会话/" class="article-date">
  <time datetime="2018-03-28T09:01:57.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/session会话/">session会话</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>session会话</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>在我们登录成功之后，我们需要把用户信息显示在页面上，并且在跳转到别的页面的时候，这个用户依然是已经登录的状态浏览器可以识别，这就需要session 会话作用域</li>
<li>django session的设计原理<ul>
<li>a、如果用户是第一次请求（就看客户端ie是否保存了sessionId的cookie）<br>创建session model <br>生成一个key sessionId 随机的一个字符串（uuid使id永远也不会重复）<br>保存到你session_engine指定位置<br>保存到cookie中，在客户的浏览器中</li>
<li>b、如果第二次以上的请求，客户端ie都会自动提交cookie到django中，django中利用你配置的SessionMiddleware中间件激活session利用cookie中的sessionID到session_engine指定位置读取session model，并设置到request的session属性上<br>正是因为这样才能在view里面通过request.session使用session</li>
<li>session只能储存json也就是字典类型的数据; session本身就是一个dict字段;session在存数据时数据必须支持序列化json</li>
</ul>
</li>
</ul>
<p></p><h6>步骤</h6><p></p>
<ul>
<li><p>1.installed_apps</p>
<pre><code>#settings.py
INSTALLED_APPS = [
    &apos;django.contrib.sessions&apos;,
]
</code></pre></li>
<li><p>2.中间件（帮我们启用session）</p>
<pre><code>#settings.py
MIDDLEWARE = [
   &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,
]
</code></pre></li>
<li><p>3.设置存储形式（储存在设置数据库中）</p>
<pre><code>makemigrations sessions
migrate
</code></pre></li>
<li><p>4.引用 request.session</p>
<pre><code>#views.py
def login(request):
    if request.method==&quot;GET&quot;:
        return render(request,&apos;login.html&apos;,{})
    else:
        username=request.POST.get(&apos;username&apos;)
        pwd=request.POST.get(&apos;pwd&apos;)
        BlogUserSet = BlogUser.objects.filter(username=username,pwd=pwd)
        if len(BlogUserSet)==1:
            session=request.session
            session[&apos;user&apos;]={&apos;username&apos;:BlogUserSet.first().username}
            return redirect(reverse(&apos;user:welcome&apos;))
            #return redirect(reverse(&apos;user:welcome&apos;,args=[BlogUserSet.first().id]))
        else:
            return render(request,&apos;login.html&apos;,{&apos;username&apos;:username,&apos;error&apos;:&apos;用户名或者密码错误！&apos;})
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/session会话/" data-id="cjffk8zye0036awwvi1jn7y8z" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-转发与重定向" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/27/转发与重定向/" class="article-date">
  <time datetime="2018-03-27T03:50:35.000Z" itemprop="datePublished">2018-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/27/转发与重定向/">转发与重定向</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>转发与重定向</h5><p></p>
<hr>
<hr>
<p></p><h6>重定向</h6><p></p>
<ul>
<li>数据库虽然已经添加了数据，但如果继续刷新浏览器数据库会保存重复的数据,这就需要重定向</li>
<li>转发：一次请求和响应，请求的地址没有发生变化，请求的数据被服务器内部的资源共享，如果此时刷新页面就会出现重做现象（服务器响应给客户的是转发）</li>
<li>重定向：一次以上的请求和响应，请求地址发生一次以上的变化。如果此时刷新页面不会出现重做现象（指向虚拟的网址页面）</li>
<li><p>需要在views.py里面导入redirect和reverse模块，然后需要在我们刷新的时候跳转到另一个页面,代码如下：</p>
<pre><code>#在bloguser/urls.py添加路径
app_name=&apos;user&apos;
urlpatterns = [
    path(&apos;register&apos;, register),
    path(&apos;welcome/&lt;int:id&gt;&apos;, welcome,name=&apos;welcome&apos;),
]

#在bloguser/views.py
def register(request):
    if request.method==&apos;GET&apos;:
        return render(request,&apos;register.html&apos;)
    elif request.method==&apos;POST&apos;:
        bloguser=BlogUser()
        bloguser.username=request.POST.get(&apos;username&apos;)
        bloguser.pwd=request.POST.get(&apos;pwd&apos;)
        bloguser.save()
        return redirect(reverse(&apos;user:welcome&apos;,args=[bloguser.id]))   #user,虚拟的命名空间，welcome，执行的函数,
def welcome(request,id):
    bloguser=BlogUser.objects.get(pk=id)
    return render(request, &apos;welcome.html&apos;, {&apos;bloguser&apos;: bloguser})

#在pyblog/urls.py下
urlpatterns = [
    path(&apos;admin/&apos;, admin.site.urls),
    path(&apos;bloguser/&apos;,include(&apos;bloguser.urls&apos;)),
    path(&apos;user/&apos;,include(&apos;bloguser.urls&apos;,namespace=&apos;user&apos;)),
]
</code></pre></li>
</ul>
<p></p><h6>重名</h6><p></p>
<ul>
<li>如果使用<code>unique=True</code>，我们必须点击提交才会告诉我们用户名重复，应该在我们输入密码的时候就告诉我们用户名重复</li>
<li><p>这时候我们需要使用ajax(ajax: jquery 是一种静态资源),不需要我们提交，当我们输入密码的时候就可以告诉我们用户名已重复</p>
<ul>
<li>1.在pyblog里面创建一个static的文件夹，接着创建js的文件夹，把jquery-3.3.1放进去</li>
<li><p>2.接着需要在setings.py里面添加static文件</p>
<pre><code>STATIC_URL = &apos;/static/&apos;
STATICFILES_DIRS=[
    os.path.join(BASE_DIR,  &apos;static&apos;)
]
</code></pre></li>
<li><p>3.在register.html中加上javascript</p>
<pre><code>&lt;script type=&quot;text/javascript&quot; src=&quot;/static/js/jquery-3.3.1.js&quot;&gt;&lt;/script&gt;
&lt;script &gt;
    $(function(){
        $(&apos;input[name=&quot;username&quot;]&apos;).blur(function(){
            uname=$(&apos;input[name=&quot;username&quot;]&apos;).val()
            CSRF=$(&quot;input[name=&apos;csrfmiddlewaretoken&apos;]&quot;).val()
            $.ajax({
                url:&apos;/bloguser/getUser&apos;,
                data:{&apos;uname&apos;:uname,&apos;csrfmiddlewaretoken&apos;:CSRF},
                type:&apos;POST&apos;,
                success:function(dat){
                    if(dat==&apos;True&apos;){
                        $(&apos;span&apos;).html(&apos;用户名已经存在！&apos;)
                    }
                    else{
                        $(&apos;span&apos;).html(&apos;用户名可以使用！&apos;)
                    }
                }
            })
        })
    })
&lt;/script&gt;
</code></pre></li>
<li><p>4.在views.py定义一个getUser(),同时需要导入HttpResponse模块，用来判断用户名有没有重复</p>
<pre><code>def getUser(request):
    uname=request.POST.get(&apos;uname&apos;)
    BlogUserSet=BlogUser.objects.filter(username=uname)
    if len(BlogUserSet)==1:
        return HttpResponse(&apos;True&apos;)
    else:
        return HttpResponse(&apos;False&apos;)
</code></pre></li>
<li><p>5.然后在bloguser\urls.py配置一下路径</p>
<pre><code>app_name=&apos;user&apos;
urlpatterns = [
    path(&apos;register&apos;, register),
    path(&apos;getUser&apos;, getUser),
    path(&apos;welcome/&lt;int:id&gt;&apos;, welcome,name=&apos;welcome&apos;),
]
</code></pre></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/27/转发与重定向/" data-id="cjffk901m004uawwvai8phvpy" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-pyspider框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/24/pyspider框架/" class="article-date">
  <time datetime="2018-03-24T10:41:19.000Z" itemprop="datePublished">2018-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/24/pyspider框架/">pyspider框架</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>pyspider框架</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>pyspider 是一个用python实现的功能强大的网络爬虫系统，能在浏览器界面上进行脚本的编写，功能的调度和爬取结果的实时查看，后端使用常用的数据库进行爬取结果的存储，还能定时设置任务与任务优先级等</li>
<li>PhantomJS 是一个基于 WebKit 的服务器端 JavaScript API。它全面支持web而不需浏览器支持，其快速、原生支持各种Web标准：DOM 处理、CSS 选择器、JSON、Canvas 和 SVG。 PhantomJS 可以用于页面自动化、网络监测、网页截屏以及无界面测试等</li>
<li>安装完pyspider、phantomJS后，在命令行输入<code>pyspider all</code>启动pyspider所有服务组件…然后浏览器访问 <a href="http://localhost:5000，" target="_blank" rel="noopener">http://localhost:5000，</a><br>如果正常出现 PySpider 的页面，那证明一切OK</li>
<li>pyspider的架构主要分为 scheduler（调度器）, fetcher（抓取器）, processor（脚本执行）,以及一个监控组件，当启动服务组件的时候，这些程序均开始运行了…<ul>
<li>1.各个组件间使用消息队列连接，除了scheduler是单点的，fetcher 和 processor 都是可以多实例分布式部署的。 scheduler 负责整体的调度控制</li>
<li>2.任务由 scheduler 发起调度，fetcher 抓取网页内容， processor 执行预先编写的python脚本，输出结果或产生新的提链任务（发往 scheduler），形成闭环</li>
<li>3.每个脚本可以灵活使用各种python库对页面进行解析，使用框架API控制下一步抓取动作，通过设置回调控制解析动作</li>
</ul>
</li>
</ul>
<p></p><h6>页面内容解析</h6><p></p>
<ul>
<li>拿www.reeoo.com这个网页，爬取上面的数据</li>
<li>创建新项目页面：<ul>
<li>Project Name：任务的名字</li>
<li>Start URL(s)：爬取任务开始的地址</li>
</ul>
</li>
<li><p>创建后的页面</p>
<pre><code>from pyspider.libs.base_handler import *
class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    #@every(minutes=24 * 60) 通知 scheduler（框架的模块） 每天运行一次
    def on_start(self):
    #on_start(self) 程序的入口，当点击左侧绿色区域右上角的 run 按钮时首先会调用这个函数
        self.crawl(&apos;https://reeoo.com/&apos;, callback=self.index_page)
    #self.crawl(url, callback) pyspider库主要的API，用于创建一个爬取任务，url 为目标地址，这里为我们刚刚创建任务指定的起始地址，callback 为抓取到数据后的回调函数

    @config(age=10 * 24 * 60 * 60)
    #@config(age=10 * 24 * 60 * 60) 设置任务的有效期限，在这个期限内目标爬取的网页被认为不会进行修改
    def index_page(self, response):
    #index_page(self, response) 参数为 Response 对象，response.doc 为 pyquery 对象，主要用来方便地抓取返回的html文档中对应标签的数据
        for each in response.doc(&apos;a[href^=&quot;http&quot;]&apos;).items():
            self.crawl(each.attr.href, callback=self.detail_page)

    @config(priority=2)
    #@config(priority=2) 设定任务优先级
    def detail_page(self, response):
    #detail_page(self, response) 返回一个 dict 对象作为结果，结果会自动保存到默认的 resultdb 中，也可以通过重载方法来将结果数据存储到指定的数据库
        return {
            &quot;url&quot;: response.url,
            &quot;title&quot;: response.doc(&apos;title&apos;).text(),
        }
</code></pre></li>
<li><p>运行代码后时出现 HTTP 599: SSL certificate problem: unable to get local issuer certificate错误时：<br><br>使用 self.crawl(url, callback=self.index_page, validate_cert=False)</p>
</li>
<li>运行<br>1.点击左边绿色区域右上角的 run 按钮，运行之后页面下册的 follows 按钮出现红色角标<br>2.选中 follows 按钮，看到 index_page 行，点击行右侧的运行按钮<br>3.运行完成后显示 www.reeoo.com 页面上所有的url<br>4.此时任意选择一个结果运行，此时调用的是 detail_page 方法，返回结果为json格式的数据，这里我们保存的是网页的 title 和 url，见左侧黑色的区域<br>5.回到主页面，此时看到任务列表显示刚刚创建的任务，设置 status 为 running，然后点击 Run 按钮执行<br>6.执行过程中可以看到整个过程的打印输出<br>7.执行完成后，点击 Results 按钮，进入到爬取结果的页面<br>8.右上方的按钮选择将结果数据保存成对应的格式，例如：JSON格式的数据</li>
</ul>
<p></p><h6>查找文件路径</h6><p></p>
<ul>
<li>由于配置了windows的环境变量，所以习惯性的打开CMD后就直接敲命令行执行 pyspider语句，但找不到pyspider存储的数据在哪里</li>
<li>后来才发现，pyspider命令行执行的时候，数据库data文件会自动在当前目录生成，即在<code>C:\Users\DELL&gt;</code>下，<code>C:\Users\DELL\data</code></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/24/pyspider框架/" data-id="cjffk8zxe002mawwvm8rloyvg" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-selenium模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/selenium模块/" class="article-date">
  <time datetime="2018-03-23T15:15:47.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/selenium模块/">selenium模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>selenium模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>selenium 是一套完整的web应用程序测试系统，Selenium的核心Selenium Core基于JsUnit，完全由JavaScript编写，因此可以用于任何支持JavaScript的浏览器上，爬虫中主要用来解决JavaScript渲染问题</li>
<li>Selenium.Webdriver支持的浏览器中，比较重要的PhantomJS,PhantomJS是一个基于WebKit的服务端JavaScript API,支持Web而不需要浏览器支持，其快速、原生支持各种Web标准：Dom处理，CSS选择器，JSON等等。PhantomJS可用于页面自动化、网络监测、网页截屏，以及无界面测试</li>
</ul>
<p></p><h6>查找元素</h6><p></p>
<ul>
<li><p>单个元素和多个元素的查找，用法基本一致</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By
from time import sleep

browser=webdriver.Chrome()
browser.get(&apos;http://www.baidu.com&apos;)  #声明浏览器对象
#print(browser.page_source)       #打印百度首页的源代码
input=browser.find_element(By.ID,&apos;kw&apos;)
input.clear()
input.send_keys(&apos;selenium&apos;)
button=browser.find_element(By.CSS_SELECTOR,&apos;#su&apos;)
button.click()
sleep(3)
browser.close()
</code></pre></li>
<li><p>这里列举一下常用的查找元素方法：</p>
<pre><code>find_element_by_name
find_element_by_id
find_element_by_xpath
find_element_by_link_text
find_element_by_partial_link_text
find_element_by_tag_name
find_element_by_class_name
find_element_by_css_selector
</code></pre></li>
</ul>
<p></p><h6>执行JavaScript</h6><p></p>
<ul>
<li><p>这是一个非常有用的方法，这里就可以直接调用js方法来实现一些操作，下面的例子是通过登录知乎然后通过js翻到页面底部，并弹框提示</p>
<pre><code>from selenium import webdriver

browser=webdriver.Chrome()
browser.get(&apos;http://www.zhihu.com/explore&apos;)  #声明浏览器对象
browser.execute_script(&apos;window.scrollTo(0,document.body.scrollHeight)&apos;)
browser.execute_script(&apos;alert(&quot;Hello World!&quot;)&apos;)
</code></pre></li>
</ul>
<p></p><h6>01</h6><p></p>
<ul>
<li><p>获取属性值、文本值</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By

browser=webdriver.Chrome()
browser.get(&apos;https://www.zhihu.com/explore&apos;)
logo=browser.find_element(By.ID,&apos;zh-top-link-logo&apos;)
print(logo.get_attribute(&apos;class&apos;))    #获取元素的属性值
print(logo.text)                      #获取文本值
print(logo.id)
print(logo.location)                  #获取位置
print(logo.tag_name)                  #获取标签名
print(logo.size)
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/selenium模块/" data-id="cjffk8zy90033awwvit9h28il" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-pyquery模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/pyquery模块/" class="article-date">
  <time datetime="2018-03-23T15:15:27.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/pyquery模块/">pyquery模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>pyquery模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>PyQuery库也是一个非常强大又灵活的网页解析库，是 Python 仿照 jQuery 的严格实现</li>
<li><p>初始化<br>初始化的时候一般有三种传入方式：传入字符串，传入url,传入文件</p>
<pre><code>from pyquery import PyQuery as pq
html=&apos;&apos;&apos;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
             &lt;p&gt;This is a paragraph.&lt;/p&gt;        
        &lt;/ul&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
###字符串初始化
doc=pq(html)      #doc其实就是一个pyquery对象
print(doc(&apos;li&apos;))  #doc(标签名)就可以获取所有的该标签的内容
print(doc(&apos;.item-0&apos;))  #doc(&apos;.class_name&apos;)，doc(&apos;#id_name&apos;)
###URL初始化
url=&apos;http://www.baidu.com&apos;
doc=pq(url,encoding=&apos;utf-8&apos;)
print(doc(&apos;head&apos;))
###文件初始化
在pq()这里可以传入url参数也可以传入文件参数，当然这里的文件通常是一个html文件，例如：pq(filename=&apos;index.html&apos;)
</code></pre></li>
</ul>
<p></p><h6>查找元素</h6><p></p>
<ul>
<li><p>子元素（children,find）</p>
<pre><code>doc=pq(html)
items=doc(&apos;.list&apos;)
lis=items.find(&apos;li&apos;)   #lis=items.children()可以实现同样的效果
print(lis)
</code></pre></li>
<li><p>父元素（parent,parents）</p>
<pre><code>doc=pq(html)
items=doc(&apos;.list&apos;)
cont=items.parent() #可以找到父元素的所有内容
#cont=items.parents()返回两部分内容，一个是父节点信息，一个是父节点的父节点的信息即祖先节点的信息
print(cont)
</code></pre></li>
<li><p>兄弟元素（siblings）</p>
<pre><code>doc=pq(html)
li=doc(&apos;.list .item-0.active&apos;)
print(li.siblings())
</code></pre></li>
<li><p>遍历</p>
<pre><code>doc=pq(html)
lis=doc(&apos;li&apos;).items()
print(type(lis))     #&lt;class &apos;generator&apos;&gt;
for li in lis:
    print(li)        #通过for循环得到的每个元素依然是一个pyquery对象
</code></pre></li>
</ul>
<p></p><h6>获取信息</h6><p></p>
<ul>
<li><p>获取属性值–pyquery对象.attr(属性名)</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-1 a&apos;)
print(a.attr(&apos;href&apos;))
</code></pre></li>
<li><p>获取文本–pyquery对象.text()</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-0.active a&apos;)
print(a.text())
</code></pre></li>
<li><p>获取html–puquery对象.html()获取当前标签所包含的html信息</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-0.active a&apos;)
print(a.html())
</code></pre></li>
</ul>
<p></p><h6>DOM操作</h6><p></p>
<ul>
<li><p>addClass、removeClass添加和删除属性值</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.addClass(&apos;2018&apos;)
ul.removeClass(&apos;2018&apos;)
print(ul)
</code></pre></li>
<li><p>attr,css给标签添加和修改属性</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.attr(&apos;id&apos;,&apos;201803&apos;)
ul.css(&apos;font-size&apos;,&apos;15px&apos;)
print(ul)         #&lt;ul class=&quot;list&quot; id=&quot;201803&quot; style=&quot;font-size: 15px&quot;&gt;
</code></pre></li>
<li><p>remove将无用的或者干扰的标签直接删除</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.find(&apos;p&apos;).remove()
print(ul.text())
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/pyquery模块/" data-id="cjffk8zxi002oawwv324zcvvg" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-beautifulsoup模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/beautifulsoup模块/" class="article-date">
  <time datetime="2018-03-23T10:31:34.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/beautifulsoup模块/">beautifulsoup模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>beautifulsoup模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>BeautifulSoup是Python的一个库，最主要的功能就是从网页爬取我们需要的数据。BeautifulSoup将html解析为对象进行处理，全部页面转变为字典或者数组，相对于正则表达式的方式，可以大大简化处理过程</li>
<li>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装</li>
<li><p>以下是这两个库的比较：</p>
<pre><code>1.Python标准库    BeautifulSoup(html,’html.parser’)    
Python内置标准库；执行速度快     容错能力较差
2.lxml HTML解析库    BeautifulSoup(html,’lxml’)    
速度快；容错能力强    需要安装，需要C语言库
</code></pre></li>
</ul>
<p></p><h6>标签选择器</h6><p></p>
<ul>
<li><p>soup.标签名，可以获得这个标签的内容；通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;html&gt;
        &lt;head&gt;
            &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;
        &lt;/head&gt;
        &lt;body&gt;
            &lt;p class=&quot;story&quot;&gt;
                Once upon a time there were three little sisters; and their names were
                &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                    &lt;span&gt;Elsie&lt;/span&gt;
                &lt;/a&gt;
                &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;
                and
                &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
                and they lived at the bottom of a well.
            &lt;/p&gt;
            &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)    #创建对象
print(soup.head.title.string)
</code></pre></li>
<li><p>基本用法</p>
<pre><code>soup.prettify()，自动补全缺失的标签
soup.标签名，可以获得这个标签的内容
soup.标签名.name，可以获得该标签的名称
soup.标签名[&apos;name&apos;]，可以获得该标签的name属性值
soup.标签名.string，可以获取第一个该标签的内容
soup.标签名.内标签名.string，嵌套方式
soup.标签名.contents，将该标签下的所有子标签存入到一个列表中
soup.标签名.parent，可以获取父节点所有信息
soup.标签名.next_sibling 获取下一个兄弟标签
soup.标签名.next_siblings 获取后面的兄弟节点
souo.标签名.previous_sinbling 获取上一个兄弟标签
soup.标签名.previous_siblings 获取前面的兄弟节点
</code></pre></li>
</ul>
<p></p><h6>标准选择器</h6><p></p>
<ul>
<li>soup.find_all(name,attrs,text)可根据标签名、属性、内容查找文档</li>
<li><p>soup.find(name,attrs,text)返回匹配结果的第一个元素</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;div class=&quot;panel&quot;&gt;
        &lt;div class=&quot;panel-heading&quot;&gt;
            &lt;h4&gt;Hello&lt;/h4&gt;
        &lt;/div&gt;
        &lt;div class=&quot;panel-body&quot;&gt;
            &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
            &lt;/ul&gt;
            &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)
for li in soup.find_all(&apos;ul&apos;):    #以针对结果再次find_all,从而获取所有的li标签信息
    print(li.find_all(&apos;li&apos;))
print(soup.find_all(attrs={&apos;class_&apos;:&apos;element&apos;}))
#attrs可以传入字典的方式来查找标签，但是这里有个特殊的就是class,因为class在python中是特殊的字段，所以如果想要查找class相关的可以更改attrs={&apos;class_&apos;:&apos;element&apos;}
</code></pre></li>
<li><p>基本用法：</p>
<pre><code>soup.find_all(&apos;标签名&apos;)  结果返回的是一个列表的方式
soup.finf_all(attrs={&apos;class_&apos;:&apos;element&apos;})
soup.find_all(text=&apos;Foo&apos;) 返回的是查到的所有的text=&apos;Foo&apos;的文本
</code></pre></li>
</ul>
<p></p><h6>CSS选择器</h6><p></p>
<ul>
<li>通过select()直接传入CSS选择器就可以完成选择</li>
<li>通过get_text()可以获取文本内容</li>
<li><p>通过 标签名[属性名] 或者 标签名.attrs[属性名]获取属性</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;div class=&quot;panel&quot;&gt;
        &lt;div class=&quot;panel-heading&quot;&gt;
            &lt;h4&gt;Hello&lt;/h4&gt;
        &lt;/div&gt;
        &lt;div class=&quot;panel-body&quot;&gt;
            &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
            &lt;/ul&gt;
            &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)
print(soup.select(&apos;#list-2 .element&apos;))
print(soup.ul[&apos;id&apos;])
for li in soup.select(&apos;li&apos;):
    print(li.get_text())     #获得文本内容
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/beautifulsoup模块/" data-id="cjffk8zwr002aawwvwf1d6ld3" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/2/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django学习/">Django学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git学习/">Git学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTTP协议/">HTTP协议</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux学习/">Linux学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB数据库/">MongoDB数据库</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL学习/">MySQL学习</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python学习/">Python学习</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis数据库/">Redis数据库</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web前端/">Web前端</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全测试/">安全测试</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/性能测试/">性能测试</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/抓包工具/">抓包工具</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫学习/">爬虫学习</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自动化测试/">自动化测试</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Django学习/" style="font-size: 12.5px;">Django学习</a> <a href="/tags/Git学习/" style="font-size: 13.75px;">Git学习</a> <a href="/tags/HTTP协议/" style="font-size: 10px;">HTTP协议</a> <a href="/tags/Linux学习/" style="font-size: 13.75px;">Linux学习</a> <a href="/tags/MongoDB数据库/" style="font-size: 12.5px;">MongoDB数据库</a> <a href="/tags/MySQL学习/" style="font-size: 15px;">MySQL学习</a> <a href="/tags/Python学习/" style="font-size: 20px;">Python学习</a> <a href="/tags/Redis数据库/" style="font-size: 16.25px;">Redis数据库</a> <a href="/tags/Web前端/" style="font-size: 18.75px;">Web前端</a> <a href="/tags/安全测试/" style="font-size: 12.5px;">安全测试</a> <a href="/tags/性能测试/" style="font-size: 11.25px;">性能测试</a> <a href="/tags/抓包工具/" style="font-size: 11.25px;">抓包工具</a> <a href="/tags/爬虫学习/" style="font-size: 17.5px;">爬虫学习</a> <a href="/tags/自动化测试/" style="font-size: 13.75px;">自动化测试</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">46</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">11</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/29/scrapy基础了解/">scrapy基础了解</a>
          </li>
        
          <li>
            <a href="/2018/03/28/网络配置、系统查看/">网络配置、系统查看</a>
          </li>
        
          <li>
            <a href="/2018/03/28/vi-vim/">vi/vim</a>
          </li>
        
          <li>
            <a href="/2018/03/28/linux常用命令/">linux常用命令</a>
          </li>
        
          <li>
            <a href="/2018/03/28/session会话/">session会话</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">About</h3>
    <div class="widget">
       Email:<a>liuyongqian51@163.com</a><br />
          QQ:<a>272501447</a><br />
	  Github:<a></a>
    </div>
  </div>

  
  

</aside>


        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 刘永前<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>

</footer>


    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>