<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>LiuYongQian</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="永远相信美好的事情将要发生！">
<meta property="og:type" content="website">
<meta property="og:title" content="LiuYongQian">
<meta property="og:url" content="http://yoursite.com/page/7/index.html">
<meta property="og:site_name" content="LiuYongQian">
<meta property="og:description" content="永远相信美好的事情将要发生！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LiuYongQian">
<meta name="twitter:description" content="永远相信美好的事情将要发生！">
  
    <link rel="alternate" href="/atom.xml" title="LiuYongQian" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiuYongQian</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">永远相信美好的事情将要发生！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-使用hadoop里面的MapReduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/16/使用hadoop里面的MapReduce/" class="article-date">
  <time datetime="2018-04-16T10:59:19.000Z" itemprop="datePublished">2018-04-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/16/使用hadoop里面的MapReduce/">使用hadoop里面的MapReduce</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>使用hadoop里面的MapReduce</h5><p></p>
<hr>
<hr>
<p></p><h6>示例：使用hadoop里面的MapReduce统计data1中有哪些内容及字段出现频率</h6><p></p>
<ul>
<li>1.普通用户（hadoop）启动服务，<code>start-all.sh</code>后在浏览器中输入：<code>python333:50070</code>，就是主机名与端口号，建立与HDFS的关联</li>
<li>2.hadoop用户在工作目录下<code>touch data1.txt</code>，并新增任意内容</li>
<li><p>3.创建文件上传后的目录</p>
<pre><code>hadoop fs -mkdir -p /user/hadoop   #-p为创建多级目录，该目录为文件上传路径
注：如果创建过程出现错误，如‘Name node is in safe mode’,需要进入hadoop-2.9.0目录下，
执行命令：bin/hadoop dfsadmin -safemode leave
</code></pre></li>
<li><p>4.将本地文件data1.txt上传到hdfs上</p>
<pre><code>hadoop fs -put data1.txt 
</code></pre></li>
<li><p>5.统计字段个数</p>
<ul>
<li><p>5.1进入/home/hadoop/opt/hadoop-2.9.0/share/hadoop/mapreduce下，执行命令：</p>
<pre><code>hadoop jar hadoop-mapreduce-examples-2.9.0.jar wordcount /user/hadoop/ /user/output
#该命令后两个路径，其中前一个为需要解析统计的文件路径，后一个为文件统计后的存放路径
</code></pre></li>
<li><p>5.2可在浏览器打开的“Browse Directory”中输入<code>/user/output</code>查看统计结果，结果的文件名为part-r-00000</p>
</li>
<li><p>5.3hadoop用户可以回到工作目录下，输入一下命令将结果文件下载到工作目录下</p>
<pre><code>hadoop fs -get /user/output/part-r-00000
</code></pre><p>5.4<code>cat part-r-00000</code>可以查看结果文件内容</p>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/16/使用hadoop里面的MapReduce/" data-id="ck6x6vi4d0063twwvgt82ymj7" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据/">大数据</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-虚拟机centos上部署hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/14/虚拟机centos上部署hadoop/" class="article-date">
  <time datetime="2018-04-14T10:10:13.000Z" itemprop="datePublished">2018-04-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/14/虚拟机centos上部署hadoop/">虚拟机centos上部署hadoop</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>虚拟机centos上部署hadoop</h5><p></p>
<hr>
<hr>
<p></p><h6>基本配置</h6><p></p>
<ul>
<li>以下1-5的操作均以root用户身份针对虚拟机中的Linux系统</li>
<li><p>1.root下分别配置静态IP、子网掩码、网关、域名解析</p>
<pre><code>IPADDR=192.168.220.128    （linux系统的IP）
NETMASK=255.255.255.0
GATEWAY=192.168.220.2    （linux系统的网关）
DNS1=202.106.0.20       （可以是这个）
</code></pre></li>
<li><p>2.root下vi /etc/sysconfig/network-scripts/ifcfg-ens33后追加如下内容：</p>
<pre><code>IPADDR=192.168.220.128
NETMASK=255.255.255.0
GATEWAY=192.168.220.2
DNS1=202.106.0.20

并修改BOOTPROTO=static
</code></pre></li>
<li><p>3.重启网络：systemctl restart network</p>
</li>
<li><p>4.root下修改主机名称<br>默认情况下的主机名:localhost，修改为python333</p>
<pre><code>vi /etc/hostname后只留存内容：python333
</code></pre><p>  修改主机映射</p>
<pre><code>vi /etc/hosts后追加内容：192.168.220.128 python333
</code></pre></li>
<li><p>5.重启linux系统，命令：reboot</p>
</li>
<li>6.修改Windows主机对虚拟机中linux系统的认知<br>在C:\Windows\System32\drivers\etc下的hosts中追加192.168.220.128 python333<br>即可以ssh python333远程登录linux</li>
</ul>
<p></p><h6>部署hadoop</h6><p></p>
<ul>
<li>以下步骤多以hadoop用户身份操作，即以普通用户操作</li>
<li><p>1.hadoop用户解压文件于/home/hadoop/opt/下,命令：tar -zvxf hadoop-xxx.gx -C opt</p>
</li>
<li><p>2.配置hadoop环境变量,hadoop用户在工作目录下vi .bashrc后追加如下内容：</p>
<pre><code>export HADOOP_HOME=/home/hadoop/opt/hadoop-2.9.0
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
</code></pre></li>
<li><p>3.之后source .bashrc刷新，输入hadoop验证</p>
</li>
<li><p>4.配置hadoop配置文件，进入/home/hadoop/opt/hadoop-2.9.0/etc/hadoop下，添加如下信息</p>
<pre><code>4.1.core-site.xml:默认文件系统hdfs，HDFS浏览器请求地址
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://python333:9000&lt;/value&gt; 
    &lt;/property&gt;

4.2.hdfs-site,xml：修改 Hadoop 文件块的默认备份数3为1
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:///home/hadoop/opt/tmp/dfs/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:///home/hadoop/opt/tmp/dfs/data&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;python333:50070&lt;/value&gt;
    &lt;/property&gt;

4.3.mapred-site.xml：启用yarn的资源调度框架，
注：需要备份cp mapred-site.xml.template mapred-site.xml
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;

4.4.yarn-site.xml：配置yarn主机  
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;python333&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;

4.5.slaves：配置dataname主机名称
    python333
</code></pre></li>
<li><p>5.root用户关闭防火墙</p>
<ul>
<li><p>5.1.选择永久关闭（临时关闭：setenforce 0）<br></p>
<pre><code>vi /etc/selinux/config后修改：SELINUX=disabled
</code></pre></li>
<li><p>5.2关闭防火墙（查看防火墙状态systemctl status firewalld）</p>
<pre><code>临时关闭 systemctl stop firewalld
永久关闭 systemctl disable firewalld
</code></pre></li>
<li><p>5.3重启电脑reboot</p>
</li>
</ul>
</li>
<li><p>6.退出管理员用户，以hadoop进入/home/hadoop/opt/下，</p>
<ul>
<li>6.1新建tmp目录：mkdir tmp</li>
<li>6.2执行hdfs文件系统格式化,输入：hdfs namenode -format</li>
</ul>
</li>
<li><p>7.配置密匙（公匙，私匙；可以在工作目录下）</p>
<ul>
<li>7.1执行ssh-keygen -t rsa，一路回车生成密匙</li>
<li>7.2想无密码登陆到哪台电脑：ssh-copy-id python333，之后输入yes确认</li>
</ul>
</li>
<li><p>8.8.验证（hadoop在工作目录下）</p>
<ul>
<li>8.1输入start-all.sh</li>
<li>8.2输入jps</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/14/虚拟机centos上部署hadoop/" data-id="ck6x6vi8o008ltwwvsmdwkwy9" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据/">大数据</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-使用LinkExtractor提取链接" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/14/使用LinkExtractor提取链接/" class="article-date">
  <time datetime="2018-04-14T10:08:49.000Z" itemprop="datePublished">2018-04-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/14/使用LinkExtractor提取链接/">使用LinkExtractor提取链接</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>使用LinkExtractor提取链接</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>在爬取一个网站时，想要爬取的数据通常分布在多个页面中，每个页面包含一部分数据以及到其他页面的链接，提取链接有使用Selector和使用LinkExtractor两种方法</li>
<li><p>使用Selector，因为链接也是页面中的数据，所以可以使用与提取数据相同的方法进行提取，在提取少量（几个）链接或提取规则比较简单时，使用Selector就足够了</p>
<pre><code>next_url = response.css(&apos;ul.pager li.next a::attr(href)&apos;).extract_first()      
if next_url:  # 如果找到下一页的url，得到绝对路径，构造新的Request 对象          
    next_url = response.urljoin(next_url) 
     yield scrapy.Request(next_url, callback=self.parse)
</code></pre></li>
<li><p>Scrapy提供了一个专门用于提取链接的类LinkExtractor，在提取大量链接或提取规则比较复杂时，使用LinkExtractor更加方便</p>
</li>
</ul>
<p></p><h6>详解</h6><p></p>
<ul>
<li><p>首先制造一个实验环境，创建两个包含多个链接的HTML页面，使用这两个HTML文本构造两个Response对象</p>
<pre><code>from scrapy.http import HtmlResponse
from scrapy.linkextractors import LinkExtractor
html1=&apos;&apos;&apos;
    &lt;html&gt;
        &lt;body&gt;      
            &lt;div id=&quot;top&quot;&gt;         
                &lt;p&gt;下面是一些站内链接&lt;/p&gt;         
                &lt;a class=&quot;internal&quot; href=&quot;/intro/install.html&quot;&gt;Installation guide&lt;/a&gt;
                &lt;a class=&quot;internal&quot; href=&quot;/intro/tutorial.html&quot;&gt;Tutorial&lt;/a&gt;         
                &lt;a class=&quot;internal&quot; href=&quot;../examples.html&quot;&gt;Examples&lt;/a&gt;      
            &lt;/div&gt;      
            &lt;div id=&quot;bottom&quot;&gt;         
                &lt;p&gt;下面是一些站外链接&lt;/p&gt;         
                &lt;a href=&quot;http://stackoverflow.com/tags/scrapy/info&quot;&gt;StackOverflow&lt;/a&gt;         
                &lt;a href=&quot;https://github.com/scrapy/scrapy&quot;&gt;Fork on Github&lt;/a&gt;      
            &lt;/div&gt;
        &lt;/body&gt;
    &lt;/html&gt;
&apos;&apos;&apos;
html2=&apos;&apos;&apos;
    &lt;html&gt;   
        &lt;head&gt;       
            &lt;script type=&apos;text/javascript&apos; src=&apos;/js/app1.js&apos;/&gt;       
            &lt;script type=&apos;text/javascript&apos; src=&apos;/js/app2.js&apos;/&gt;   
        &lt;/head&gt;   
        &lt;body&gt;       
            &lt;a href=&quot;/home.html&quot;&gt;主页&lt;/a&gt;       
            &lt;a href=&quot;javascript:goToPage(&apos;/doc.html&apos;); return false&quot;&gt;文档&lt;/a&gt;       
            &lt;a href=&quot;javascript:goToPage(&apos;/example.html&apos;); return false&quot;&gt;案例&lt;/a&gt;   
        &lt;/body&gt;
    &lt;/html&gt;
&apos;&apos;&apos;
response1=HtmlResponse(url=&apos;http://example1.com&apos;,body=html1,encoding=&apos;utf-8&apos;)
response2=HtmlResponse(url=&apos;http://example2.com&apos;,body=html2,encoding=&apos;utf-8&apos;)
</code></pre></li>
<li><p>特例情况，LinkExtractor构造器的所有参数都有默认值，如果构造对象时不传递任何参数（使用默认值），就提取页面中所有链接</p>
<pre><code>le=LinkExtractor()
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中所有链接，5个
</code></pre></li>
<li><p>allow<br>接收一个正则表达式或一个正则表达式列表，提取绝对url与正则表达式匹配的链接</p>
<pre><code>示例　提取页面example1.html中路径以/intro开始的链接：
pattern=r&apos;/intro/.+.html$&apos;
le=LinkExtractor(allow=pattern)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中2个以/intro开始的链接
</code></pre></li>
<li><p>deny<br>接收一个正则表达式或一个正则表达式列表，与allow相反，排除绝对url与正则表达式匹配的链接</p>
<pre><code>示例　提取页面example1.html中所有站外链接（即排除站内链接）
pattern=r&apos;.*.html$&apos;
le=LinkExtractor(deny=pattern)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中2个站外链接
</code></pre></li>
<li><p>allow_domains<br>接收一个域名或一个域名列表，提取到指定域的链接</p>
<pre><code>示例　提取页面example1.html中所有到github.com和stackoverflow.com这两个域的链接
domains=[&apos;stackoverflow.com&apos;,&apos;github.com&apos;]
le=LinkExtractor(allow_domains=domains)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中2个站外链接
</code></pre></li>
<li><p>deny_domains<br>接收一个域名或一个域名列表，与allow_domains相反,排除到指定域的链接</p>
<pre><code>示例　提取页面example1.html中除了到github.com域以外的链接
domains=[&apos;github.com&apos;]
le=LinkExtractor(deny_domains=domains)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中除了github外的4个链接
</code></pre></li>
<li><p>restrict_xpaths<br>接收一个XPath表达式或一个XPath表达式列表，提取XPath表达式选中区域下的链接</p>
<pre><code>示例　提取页面example1.html中&lt;div id=&quot;top&quot;&gt;元素下的链接：
le=LinkExtractor(restrict_xpaths=&apos;//div[@id=&quot;top&quot;]&apos;)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中3个站内链接
</code></pre></li>
<li><p>restrict_css<br>接收一个CSS选择器或一个CSS选择器列表，提取CSS选择器选中区域下的链接</p>
<pre><code>示例　提取页面example1.html中&lt;div id=&quot;bottom&quot;&gt;元素下的链接
le=LinkExtractor(restrict_css=&apos;#bottom&apos;)
links=le.extract_links(response1)
print([link.url for link in links])   #打印出html1中2个站外链接
</code></pre></li>
<li><p>tags<br>接收一个标签（字符串）或一个标签列表，提取指定标签内的链接，默认为[‘a’, ‘area’]<br>attrs<br>接收一个属性（字符串）或一个属性列表，提取指定属性内的链接，默认为[‘href’]</p>
<pre><code>示例　提取页面example2.html中引用JavaScript文件的链接
le=LinkExtractor(tags=&apos;script&apos;,attrs=&apos;src&apos;)
links=le.extract_links(response2)
print([link.url for link in links])   #打印出html2中2个script链接
</code></pre></li>
<li><p>process_value<br>接收一个形如func(value)的回调函数。如果传递了该参数，LinkExtractor将调用该回调函数对提取的每一个链接（如a的href）进行处理，回调函数正常情况下应返回一个字符串（处理结果），想要抛弃所处理的链接时，返回None</p>
<pre><code>示例　在页面example2.html中，某些a的href属性是一段JavaScript代码，代码中包含了链接页面的实际url地址，此时应对链接进行处理，提取页面example2.html中所有实际链接
import re
def process(value):
    m=re.search(&quot;javascript:goToPage\(&apos;(.*?)&apos;&quot;,value)
    if m:
        value=m.group(1)
    return value
le=LinkExtractor(process_value=process)
links=le.extract_links(response2)
print([link.url for link in links])   #打印出html2中a标签中的3个链接
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/14/使用LinkExtractor提取链接/" data-id="ck6x6vi47005ztwwvi3wdz6q0" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-linux文件的打包、压缩" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/12/linux文件的打包、压缩/" class="article-date">
  <time datetime="2018-04-12T13:37:47.000Z" itemprop="datePublished">2018-04-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/12/linux文件的打包、压缩/">linux文件的打包、压缩</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>linux文件的打包、压缩</h5><p></p>
<hr>
<hr>
<p></p><h6>Linux常见的压缩文件扩展名</h6><p></p>
<ul>
<li>.gz　　    gzip压缩的文件</li>
<li>.bz2　　    bzip2压缩的文件</li>
<li>.tar　　    tar程序打包的文件</li>
<li>.tar.gz　　tar程序打包，gzip压缩的文件</li>
<li>.tar.bz2　　tar程序打包，bzip2压缩的文件</li>
</ul>
<p></p><h6>gzip命令</h6><p></p>
<ul>
<li><p>使用最广的解压缩命令，可以解开zip，gzip压缩过的文件</p>
<pre><code>gzip  [-cdtv#]  [文件名] &gt; [压缩后文件名]
-c　　：将压缩的数据输出到屏幕上，通过数据流重定向来处理
-d　　：解压缩参数
-t　　：用来检验压缩文件的一致性，看看文件是否有错误
-v　　：输出文件压缩比等信息
-#　　：压缩等级０－９，１－９压缩比增大速度变慢，默认为６
</code></pre></li>
<li><p>示例</p>
<pre><code>gzip -cv data1.txt &gt; data1.gz  (压缩)
gzip -d data1.gz               (解压)
</code></pre></li>
</ul>
<p></p><h6>bzip2命令</h6><p></p>
<ul>
<li><p>比gzip压缩更好的压缩命令</p>
<pre><code>bzip2   [-cdkzv#]　文件名
-c　　：将压缩过程中产生的数据输出到屏幕上
-d　　：解压缩的参数
-k　　：保留原文件
-z　　：压缩的参数
-v　　:可以显示出原文件/压缩文件的压缩比
-#　　：同gzip
</code></pre></li>
<li><p>示例</p>
<pre><code>如果使用的linux的版本是centos7的话需要yum install bzip2
bzip2 -kzv data.txt      (压缩)
bzip2 -d data.txt.bz2    (解压)
</code></pre></li>
</ul>
<p></p><h6>tar命令</h6><p></p>
<ul>
<li><p>哈哈，这个比较多，也更加实用</p>
<pre><code>tar　[-j|z]  [-cv]  [-f  新建的文件名]  filename 　　//打包与压缩
tar  [-j|z]  [-tv]  [-f  新建的文件名]  filename　　//查看文件名
tar  [-j|z]　[-xv]  [-f  新建的文件名]　[-C 目录]　　//解压缩

参数：
-c　　：新建打包文件
-t　　：查看打包文件的内容中有那些文件名
-x　　：解打包或解压缩
以上3条不可出现在同一串命令中
-j　　：通过bzip2的支持来压缩/解压缩
-z　　：通过gzip的支持来压缩/解压缩
-v　　：压缩/解压缩过程中显示正在处理的文件名
-f　　：后面接要处理的文件名
-C　　：特定目录解压
-p　　：保留备份数据的　原本权限与属性
</code></pre></li>
<li><p>重点说一下常用到的命令</p>
<pre><code>gzip压缩：tar  -zcvf  filename.tar.gz  要压缩的文件目录或名称
gzip解压：tar  -zxvf  filename.tar.gz　-C　解压的目录
gzip查看：tar  -zcvf  filename.tar.gz　
bzip2压缩：tar  -jcvf  filename.tar.bz2  要压缩的文件目录或名称
bzip2解压：tar  -jxvf  filename.tar.bz2　-C　解压的目录
bzip2查看：tar  -jcvf  filename.tar.bz2　
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/12/linux文件的打包、压缩/" data-id="ck6x6vi1v004htwwvwie6x2cf" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-jdk部署" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/11/jdk部署/" class="article-date">
  <time datetime="2018-04-11T11:48:13.000Z" itemprop="datePublished">2018-04-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/11/jdk部署/">jdk部署</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>jdk部署</h5><p></p>
<hr>
<hr>
<p></p><h6>echo遍历、输出、打印</h6><p></p>
<ul>
<li><p>输出</p>
<pre><code>name=&apos;hadoop&apos;(定义变量)
echo $name（输出变量值）
</code></pre></li>
<li><p>重定向、覆盖</p>
<pre><code>touch data1.txt(里面有内容)
echo ookk &gt; data1.txt(此时文件中内容被“ookk”覆盖)
</code></pre></li>
<li><p>追加</p>
<pre><code>touch data2.txt(里面有内容)
echo ookk &gt;&gt;data2.txt(此时文件末尾追加字段“ookk”)
</code></pre></li>
</ul>
<p></p><h6>jdk部署</h6> <p></p>
<ul>
<li><p>按照课堂讲解内容整理</p>
<pre><code>1.root下新建用户useradd hadoop,并给用户hadoop设置密码passwd hadoop
2.切换到hadoop下，su hadoop之后cd /home/hadoop下，即工作区；或者使用hadoop登录，默认进入工作区
3.新建目录mkdir opt
4.将文件jdk-8u152-linux-x64.tar.gz解压到opt目录下，命令为：
tar -zvxf jdk-8u152-linux-x64.tar.gz -C /home/hadoop/opt
5.配置jdk（两种方式）
    第一种：在hadoop的主目录下，vi .bashrc后添加：
        export JAVA_HOME=/home/hadoop/opt/jdk1.8.0_152
        export PATH=$JAVA_HOME/bin:$PATH
        source ~/.bashrc刷新
    第二种：以追加的形式，hadoop用户
        cd /opt/jdk1.8.0_152下，
        设置变量java_home=`pwd`，
        echo export JAVA_HOME=$java_home &gt;&gt; ~/.bashrc
        echo export PATH=\$JAVA_HOME\/bin:\$PATH &gt;&gt; ~/.bashrc
        追加之后刷新source ~/.bashrc
6.输入java -version查看是否配置成功
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/11/jdk部署/" data-id="ck6x6vi10003ytwwv2vrxr7o7" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-chmod" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/09/chmod/" class="article-date">
  <time datetime="2018-04-09T10:05:31.000Z" itemprop="datePublished">2018-04-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/09/chmod/">chmod</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>chmod</h5><p></p>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>chmod(Change mode) 用来将每个文件的模式更改为指定值。Linux/Unix 的档案调用权限分为三级 : 档案拥有者、群组、其他<ul>
<li>u:目录或者文件的当前的用户</li>
<li>g:目录或者文件的当前的群组</li>
<li>o:除了目录或者文件的当前用户或者群组之外的用户或者群组</li>
<li>a:所有的用户和群组</li>
</ul>
</li>
<li>Linux的文件基本上分为三个属性：可读(r)，可写(w)，可执行(x)<ul>
<li>权限对文件的重要性<ul>
<li>r (read) 4：可读取此文件的实际内容，如读取文本文件的文字内容等 </li>
<li>w (write) 2：可以编辑、新增或者是修改该文件的内容(但不含删除该文件)</li>
<li>x (execute) 1：该文件具有可以被系统执行的权限。linux下文件是否可以执行和扩展名无关</li>
</ul>
</li>
<li>权限对目录的重要性<ul>
<li>r：表示具有读取目录结构列表的权限，可以查询该目录下的文件名数据，可以利用 ls 这个指令将该目录的内容列表显示出来</li>
<li>w：表示具有移动该目录结构列表的权限，也就是这些权限：<ul>
<li>建立新的文件与目录</li>
<li>删除已经存在的文件与目录(不论该文件的权限为何！) </li>
<li>将已存在的文件或目录进行更名</li>
<li>搬移该目录内的文件、目录位置</li>
</ul>
</li>
<li>x：目录不可以被执行，目录的x代表的是用户能否进入该目录成为工作目录的用途！ 所谓的工作目录(work directory)就是你目前所在的目录！举例来说，当你登入Linux时， 你所在的家目录就是你当下的工作目录</li>
</ul>
</li>
<li>以rwx(Owner)r-x(Group)r-x(Other)为例：这个例子表示的权限是：使用者自己可读，可写，可执行;同一组的用户可读，不可写，可执行;其它用户可读，不可写，可执行</li>
</ul>
</li>
<li>使用权限 : 所有使用者</li>
</ul>
<p></p><h6>使用</h6><p></p>
<ul>
<li>文字设定法<ul>
<li>chmod [u、g、o、a] [+（加入）、-（除去）、=（设定）] [r、w、x] [文件或者目录]</li>
</ul>
</li>
<li>数字设定法<ul>
<li>按照顺序（u）（g）（o），将权限转换成3个从0到7的八进制数字，如若要rwx属性则4+2+1=7 ; 若要rw-属性则4+2=6</li>
</ul>
</li>
</ul>
<p></p><h6>示例</h6><p></p>
<ul>
<li><p>查看权限ll</p>
<pre><code>-rw-r--r-- 1 root root 0 4月  24 15:24 backup.sh
</code></pre></li>
<li><p>将backup.sh设定为只有该档案拥有者可以执行</p>
<pre><code>chmod u+x backup.sh
</code></pre></li>
<li><p>同时修改不同用户权限</p>
<pre><code>chmod ug+w,o-x backup.sh
</code></pre></li>
<li><p>删除文件权限</p>
<pre><code>chmod a-x backup.sh
</code></pre></li>
<li><p>使用“=”设置权限</p>
<pre><code>chmod u=x backup.sh
</code></pre></li>
<li><p>根据数字修改权限</p>
<pre><code>chmod 745 backup.sh
</code></pre></li>
<li><p>将目前目录下的所有档案与子目录皆设为任何人可读取</p>
<pre><code>chmod -R a+r *
</code></pre></li>
</ul>
<p>##参考大神佳作<a href="https://www.cnblogs.com/xqzt/p/5433022.html" target="_blank" rel="noopener">每天一个linux命令:chmod</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/09/chmod/" data-id="ck6x6vi0q003rtwwv55dznaaa" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-爬虫之Mongodb常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/08/爬虫之Mongodb常用命令/" class="article-date">
  <time datetime="2018-04-08T00:16:31.000Z" itemprop="datePublished">2018-04-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/08/爬虫之Mongodb常用命令/">爬虫之Mongodb常用命令</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>爬虫之Mongodb常用命令</h5><p></p>
<hr>
<hr>
<p></p><h6>连接数据库</h6><p></p>
<ul>
<li>连接数据库，参数为空的话默认ip为localhost，端口为27017</li>
<li><p>一下三种结果都一样</p>
<pre><code>from pymongo import MongoClient
import datetime
client=MongoClient()
client=MongoClient(&apos;localhost&apos;,27017)
client=MongoClient(&apos;mongodb://localhost:27017/&apos;)  #使用url格式连接数据库
</code></pre></li>
<li><p>连接指定的数据库</p>
<pre><code>db=client.firstdb
db=client[&apos;firstdb&apos;]
</code></pre></li>
<li><p>连接指定的集合</p>
<pre><code>test1=db.student
test1=db[&apos;student&apos;]
</code></pre></li>
</ul>
<p></p><h6>插入文档</h6><p></p>
<ul>
<li><p>插入单条文档</p>
<pre><code>data1={
    &apos;name&apos;:&apos;gouzenggong&apos;,
    &apos;text&apos;:&apos;MY first blog post&apos;,
    &apos;tags&apos;:[&apos;mongo&apos;,&apos;python&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    }
test1.insert_one(data1)
</code></pre></li>
<li><p>查找单条文档</p>
<pre><code>test1.find_one()
test1.find_one({&apos;name&apos;:&apos;gouzenggong&apos;})   #指定条件查询，如果未查到，返回空

#如果指定id查询，则需要这样做
from bson.objectid import ObjectId
test1.find_one({&apos;_id&apos;:ObjectId(&apos;5ac8df4eb09c061dfc517988&apos;)})
</code></pre></li>
<li><p>插入多条文档</p>
<pre><code>data2=[
    {
    &apos;name&apos;:&apos;zhangsan&apos;,
    &apos;text&apos;:&apos;MY second blog post&apos;,
    &apos;tags&apos;:[&apos;python&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    },
    {
    &apos;name&apos;:&apos;gouzenggong&apos;,
    &apos;text&apos;:&apos;MY three blog post&apos;,
    &apos;tags&apos;:[&apos;mongo&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    }
]
test1.insert_many(data2)
</code></pre></li>
<li><p>查找多条文档</p>
<pre><code>#查询所有结果
for i in test1.find():
    print(i)

#查询指定结果
for i in test1.find({&apos;name&apos;:&apos;gouzenggong&apos;}):
    print(i)

#查询总数
test1.count()

#查询指定的条数
test1.find({&apos;name&apos;:&apos;gouzenggong&apos;}).count()
</code></pre></li>
</ul>
<p></p><h6>更新文档</h6><p></p>
<ul>
<li><p>如果有找到x=1，则改成x=3，否则插入{‘x’:3}，单条</p>
<pre><code>test2=db.teacher    #连接一个新的集合
data3=[
    {&apos;x&apos;:1},{&apos;x&apos;:1},{&apos;x&apos;:1}
]
test2.insert_many(data3)

test2.update_one({&apos;x&apos;:1},{&apos;$set&apos;:{&apos;x&apos;:3}},upsert=True) #可以发现已经把其中一条改为x=3
</code></pre></li>
<li><p>如果找到x=4，则改成x=333，否则插入{‘x’:333}，单条</p>
<pre><code>#文档中是没有x=4的
test2.update_one({&apos;x&apos;:4},{&apos;$set&apos;:{&apos;x&apos;:333}},upsert=True) #可以发现新增了一条{&apos;x&apos;:333}
</code></pre></li>
<li><p>如果找到x=1，则改成x=’many’，否则插入{‘x’:’many’}，多条</p>
<pre><code>test2.update_many({&apos;x&apos;:1},{&apos;$set&apos;:{&apos;x&apos;:&apos;many&apos;}},upsert=True) #可以发现已经把所有x=1改成了x=many
</code></pre></li>
<li><p>如果找到x=4，则改成{‘x’:1,’y’；2}，否则插入{‘x’:1,’y’:2}，多条</p>
<pre><code>#文档中是没有x=4的
test2.update_many({&apos;x&apos;:4},{&apos;$set&apos;:{&apos;x&apos;:1,&apos;y&apos;:2}},upsert=True) #可以发现新增一条文档
</code></pre></li>
</ul>
<p></p><h6>小结</h6><p></p>
<ul>
<li>爬虫常用到的三条插入语句：（以test2为集合名）<ul>
<li>test2.insert_one(data)  插入一条文档</li>
<li>test2.insert_many(data-list) 插入多条文档</li>
<li>test2.update_one({‘x’:1},{‘$set’:{‘x’:3}},upsert=True)一般会在防止重复性的数据被存放到数据库内要用的</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/08/爬虫之Mongodb常用命令/" data-id="ck6x6vi810087twwvfvk1bo2c" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-富文本、分页" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/03/富文本、分页/" class="article-date">
  <time datetime="2018-04-03T00:05:22.000Z" itemprop="datePublished">2018-04-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/03/富文本、分页/">富文本、分页</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>富文本、分页</h5><p></p>
<hr>
<hr>
<p></p><h6>富文本</h6><p></p>
<ul>
<li>1.下载链接:  <a href="http://ueditor.baidu.com/website/download.html#ueditor,目前最新版本是ueditor-1.4.3.3" target="_blank" rel="noopener">http://ueditor.baidu.com/website/download.html#ueditor,目前最新版本是ueditor-1.4.3.3</a></li>
<li>2.将下载的文件全部存放在我们的django项目里面，路径为static/ueditor/下</li>
<li>3.将uecontroller.py文件放在与项目同名的文件夹下，该文件为格式文本请求地址，请求资源；需要将其中的依据引用代码稍做修改<code>import pyblog.settings as settings</code>，即引入项目的设置</li>
<li><p>4.在于项目同名的文件夹下的urls.py中设置路由</p>
<pre><code>from .uecontroller import handler
urlpatterns = [
    path(&apos;uecontroller&apos;,handler),
]
</code></pre></li>
<li><p>5.将ueditor/jsp/config.json文件复制到项目根目录下</p>
</li>
<li><p>6.将文件ueditor/_example/submitFormDemo.html中的部分script内容复制到前端页面fabu.html中，并且修改路径，其中博客页面中的内容标签需要加id，serverUrl</p>
<pre><code>&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;欢迎发布博客&lt;/title&gt;
    &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/static/ueditor/ueditor.config.js&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/static/ueditor/_examples/editor_api.js&quot;&gt;&lt;/script&gt;
    &lt;style type=&quot;text/css&quot;&gt;
        body{
            font-size:14px;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h2&gt;欢迎{{ user.username }}发布博客...&lt;/h2&gt;
    &lt;span style=&quot;color:red&quot;&gt;{{ msg }}&lt;/span&gt;
    &lt;form action=&quot;/pyblogA/fabu&quot; method=&quot;post&quot;&gt;
        {% csrf_token %}
        &lt;p&gt;标题：&lt;input type=&quot;text&quot; name=&apos;title&apos; style=&quot;width:500px&quot;&gt;&lt;/p&gt;
        &lt;p&gt;内容：&lt;textarea  id=&quot;myEditor&quot; name=&apos;context&apos; style=&quot;width:600px;height:400px&quot;&gt;&lt;/textarea&gt;&lt;/p&gt;
        &lt;input type=&quot;submit&quot; value=&quot;确认发布&quot;&gt;
    &lt;/form&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
        var editor_a = UE.getEditor(&apos;myEditor&apos;,{initialFrameHeight:300,serverUrl:&apos;/uecontroller&apos;});
    &lt;/script&gt;
&lt;/body&gt;
</code></pre></li>
<li><p>7.打开文件ueditor/_examples/editor_api.js，将baseURL的路径改为当前_src的路径，即<code>baseURL = &#39;/static/ueditor/_src/&#39;;</code></p>
</li>
<li><p>8.新建上传文件存储路径为static/upload/imgs/，并修改uecontroller.py中的代码</p>
<pre><code>try:
    #重新定义上传图片的名字
    truelyName = buildFileName(filename)
    webUrl = config.SavePath+ truelyName
    print(webUrl)
    #!!!!!!!!!!!!
    savePath =R&apos;static/upload/imgs/&apos;+webUrl
    # savePath =ROOT+webUrl
    print(&apos;savePath&apos;,savePath)
    f = codecs.open(savePath,&quot;wb+&quot;)
    for chunk in buf.chunks():
        f.write(chunk)
    f.flush()
    f.close()
    result.state = &quot;SUCCESS&quot;
    #返回富文本显示的图片路径
    result.url =&apos;/static/upload/imgs/&apos;+truelyName# truelyName
    print(&apos;truelyName&apos;, truelyName)
    result.title = truelyName
    result.original = truelyName
    response = HttpResponse(buildJsonResult(result))
    response[&quot;Content-Type&quot;] = &quot;text/plain&quot;
    return response
</code></pre></li>
</ul>
<p></p><h6>在登录成功欢迎页面显示博客列表，并链接进入博客页面</h6><p></p>
<ul>
<li><p>1.在发布博客的views.py中写入getAll函数</p>
<pre><code>def getAll():
    Blogset=Blog.objects.values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;BlogUser__username&apos;).all()
    return Blogset
</code></pre></li>
<li><p>2.在用户的views.py中</p>
<pre><code>from pyblogA.views import getAll
def welcome(request):
    Blogset=getAll()
    return render(request, &apos;welcome.html&apos;,
                  {&apos;user&apos;: request.session.get(&apos;user&apos;, None),
                   &apos;Blogset&apos;:Blogset
                   })
</code></pre></li>
<li><p>3.在登录欢迎页面welcome.html页面</p>
<pre><code>{% for foo in Blogset %}
		        <li>{{ foo.id }}&nbsp;&nbsp;
		            <a href="/pyblogA/showOne?id={{ foo.id }}">{{ foo.title }}</a>&nbsp;&nbsp;
		            {{ foo.createDate|date:'Y-m-d H:i:s' }}&nbsp;&nbsp;{{ foo.BlogUser__username }}
		        </li>
		{% endfor %}
</code></pre></li>
<li><p>4.接下来是链接进入博客页面，设置博客显示页面b.html</p>
<pre><code>&lt;body&gt;
    登录用户/非登录用户都可见
    &lt;!--某个文档的显示页面--&gt;
    &lt;h2&gt;标题：{{ blog.title }}&lt;/h2&gt;
    &lt;h3&gt;发布时间：{{ blog.createDate|date:'Y-m-d H:i:s' }}&lt;/h3&gt;
    &lt;h3&gt;作者：{{ blog.BlogUser__username }}&lt;/h3&gt;
    &lt;h2&gt;内容：&lt;/h2&gt;
    &lt;div style=&quot;width:85%;margin:0 auto&quot;&gt;
        {% autoescape off %}  #转义，否则显示编码
		            {{ blog.context }}
		        {% endautoescape %}
    &lt;/div&gt;
&lt;/body&gt;
</code></pre></li>
<li><p>5.在发布博客的urls中设置路径</p>
<pre><code>urlpatterns = [
    path(&apos;showOne&apos;,showOne),
]
</code></pre></li>
<li><p>6.在发布博客的views中定义showOne函数</p>
<pre><code>def showOne(request):
    id=request.GET.get(&apos;id&apos;,None)
    if id is None:
        return render(request,&apos;welcome.html&apos;)
    else:
        blog=Blog.objects.\
            values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;context&apos;,&apos;BlogUser__username&apos;).\
            filter(pk=id).all()
        return render(request,&apos;b.html&apos;,{&apos;blog&apos;:blog.first()})
</code></pre></li>
</ul>
<p></p><h6>分页</h6><p></p>
<ul>
<li><p>1.设置发布博客的views中的getAll函数</p>
<pre><code>from django.core.paginator import Paginator
def getAll(num):
    Blogset=Blog.objects.values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;BlogUser__username&apos;).all()
    paginator = Paginator(Blogset,5)  # 创建分页器
    page=paginator.get_page(num)
    return page,paginator
</code></pre></li>
<li><p>2.在用户的views.py中</p>
<pre><code>def welcome(request):
    num=request.GET.get(&apos;num&apos;,1)
    Blogset=getAll(num)[0]
    paginator=getAll(num)[1]
    return render(request, &apos;welcome.html&apos;,
                  {&apos;user&apos;: request.session.get(&apos;user&apos;, None),
                   &apos;Blogset&apos;:Blogset,
                   &apos;paginator&apos;:paginator
                   })
</code></pre></li>
<li><p>3.在登录欢迎页面welcome.html页面中</p>
<pre><code>&lt;body&gt;
    {% if Blogset.has_previous %}
		        <a href="?num=1">首页</a>
		        <a href="?num={{ Blogset.previouse_page_number }}">上一页</a>
		    {% endif %}
    {% if Blogset.has_next %}
		        <a href="?num={{ Blogset.next_page_number }}">下一页</a>
		        <a href="?num={{ paginator.num_pages }}">尾页</a>
		    {% endif %}
&lt;/body&gt;
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/03/富文本、分页/" data-id="ck6x6vi6n007ftwwv3avtt2bt" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy选择器css、xpath" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/scrapy选择器css、xpath/" class="article-date">
  <time datetime="2018-04-02T13:33:47.000Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/scrapy选择器css、xpath/">scrapy选择器css、xpath</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy选择器css、xpath</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>Scrapy自带了提取数据的机制。它们称为选择器，因为它们“选择”由XPath或CSS表达式指定的HTML文档的某些部分</li>
<li>XPath是用于选择XML文档中的节点的语言，其也可以与HTML一起使用</li>
<li>CSS是一种用于将样式应用于HTML文档的语言。它定义了选择器以将这些样式与特定的HTML元素相关联</li>
<li>Scrapy选择器构建在lxml库之上，这意味着它们的速度和解析精度非常相似</li>
</ul>
<p></p><h6>使用选择器</h6><p></p>
<ul>
<li><p>为了解释如何使用选择器，我们将使用Scrapy shell（提供交互式测试）和位于Scrapy文档服务器中的示例页面：<a href="http://doc.scrapy.org/en/latest/_static/selectors-sample1.html" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest/_static/selectors-sample1.html</a></p>
<pre><code>#打开shell
scrapy shell http://doc.scrapy.org/en/latest/_static/selectors-sample1.html 
#使用XPath和CSS选择标题标签中的文本:
response.xpath(&apos;//title/text()&apos;)
&gt;&gt;&gt;[&lt;Selector xpath=&apos;//title/text()&apos; data=&apos;Example website&apos;&gt;]
response.css(&apos;title::text&apos;)
&gt;&gt;&gt;[&lt;Selector xpath=&apos;descendant-or-self::title/text()&apos; data=&apos;Example website&apos;&gt;]
#.css()方法返回一个 SelectorList实例，它是新的选择列表。此API可用于快速选择嵌套数据：
response.css(&apos;img&apos;).xpath(&apos;@src&apos;).extract()
#要实际提取文本数据，必须调用选择器.extract() 方法,如果只想提取第一个匹配的元素，可以调用选择器 .extract_first()
response.xpath(&apos;//title/text()&apos;).extract()
response.xpath(&apos;//div[@id=&quot;images&quot;]/a/text()&apos;).extract_first()
#可以提供默认返回值作为参数
response.xpath(&apos;//div[@id=&quot;not-exists&quot;]/text()&apos;).extract_first(default=&apos;not-found&apos;)
</code></pre></li>
<li><p>Xpath选择器常用方法</p>
<pre><code>nodeName    选取此节点的所有节点
/           从根节点选取
//          从匹配选择的当前节点选择文档中的节点，不考虑它们的位置
.           选择当前节点
..          选取当前节点的父节点
@           选取属性
*           匹配任何元素节点
@*          匹配任何属性节点
Node()      匹配任何类型的节点
</code></pre></li>
<li><p>CSS选择器常用方法</p>
<pre><code>.class              .color              选择class=”color”的所有元素
#id                 #info               选择id=”info”的所有元素
*                   *                   选择所有元素
element             p                   选择所有的p元素
element,element     div,p               选择所有div元素和所有p元素
element element     div p               选择div标签内部的所有p元素
[attribute]         [target]            选择带有targe属性的所有元素
[arrtibute=value]   [target=_blank]     选择target=”_blank”的所有元素
</code></pre></li>
<li><p>获取基本URL和一些图像链接</p>
<pre><code>response.xpath(&apos;//base/@href&apos;).extract()
response.css(&apos;base::attr(href)&apos;).extract()

response.xpath(&apos;//a[contains(@href, &quot;image&quot;)]/@href&apos;).extract()
response.css(&apos;a[href*=&quot;image&quot;]::attr(href)&apos;).extract()
#其中a[href*=&quot;image&quot;]表示href的属性值包含“image”的所有a元素

response.xpath(&apos;//a[contains(@href, &quot;image&quot;)]/img/@src&apos;).extract()
response.css(&apos;a[href*=image] img::attr(src)&apos;).extract()
</code></pre></li>
</ul>
<h3 id="参考大神佳作Scrapy爬虫入门教程五-Selectors（选择器）"><a href="#参考大神佳作Scrapy爬虫入门教程五-Selectors（选择器）" class="headerlink" title="参考大神佳作Scrapy爬虫入门教程五 Selectors（选择器）"></a>参考大神佳作<a href="https://blog.csdn.net/Inke88/article/details/60589170" target="_blank" rel="noopener">Scrapy爬虫入门教程五 Selectors（选择器）</a></h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/scrapy选择器css、xpath/" data-id="ck6x6vi3h005jtwwvo31c4vfy" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy命令行详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/scrapy命令行详解/" class="article-date">
  <time datetime="2018-04-02T11:08:41.000Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/scrapy命令行详解/">scrapy命令行详解</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy命令行详解</h5><p></p>
<hr>
<hr>
<ul>
<li><p>创建项目<code>scrapy startproject 项目名</code></p>
<pre><code>#测试网站：http://quotes.toscrape.com/
scrapy startproject quotetutorial
</code></pre></li>
<li><p>创建爬虫<code>scrapy genspider spider文件名 网站域名</code></p>
<pre><code>cd quotetutorial         进入项目
scrapy genspider quotes quotes.toscrape.com   创建爬虫
</code></pre></li>
<li><p>运行爬虫<code>scrapy crawl 爬虫文件名</code></p>
<pre><code>scrapy crawl quotes
scrapy crawl quotes -o quotes.json   保存爬取数据为json格式,还有其他格式如.jl、.csv、.xml、.pickle、.marshal等等
</code></pre></li>
<li><p>在项目中常用的其他命令（局部命令）</p>
<pre><code>scrapy check   检查spider文件有无语法错误
scrapy list    列出spider路径下的spider文件
scrapy bench   测试电脑当前爬取速度性能，即基准测试
</code></pre></li>
</ul>
<ul>
<li><p>全局命令</p>
<pre><code>scrapy fetch &lt;url&gt;  将网页内容下载下来，然后在终端打印当前返回的内容
scrapy view &lt;url&gt;   将网页内容保存下来，并在浏览器中打开当前网页内容，直观呈现要爬取网页的内容（发现这个与上述命令效果一样啊）
scrapy shell [url]  打开 scrapy 显示台，进入命令行交互模式
可以用来做测试,（exit()退出模式）
scrapy version [-v]  显示scrapy版本，后面加 -v 可以显示scrapy依赖库的版本
scrapy runspider &lt;spider_file.py&gt;  运行一个自包含在Python文件中的爬虫，而不必创建一个项目
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/scrapy命令行详解/" data-id="ck6x6vi3e005htwwv2he86of1" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/6/">&laquo; zurück</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/8/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django学习/">Django学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA项目部署/">JAVA项目部署</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux学习/">Linux学习</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL学习/">MySQL学习</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx学习/">Nginx学习</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NoSQL学习/">NoSQL学习</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python学习/">Python学习</a><span class="tag-list-count">27</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web前端/">Web前端</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全测试/">安全测试</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/性能测试/">性能测试</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫学习/">爬虫学习</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络基础知识/">网络基础知识</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自动化测试/">自动化测试</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件工具/">软件工具</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Django学习/" style="font-size: 11.82px;">Django学习</a> <a href="/tags/JAVA项目部署/" style="font-size: 17.27px;">JAVA项目部署</a> <a href="/tags/Linux学习/" style="font-size: 19.09px;">Linux学习</a> <a href="/tags/MySQL学习/" style="font-size: 18.18px;">MySQL学习</a> <a href="/tags/Nginx学习/" style="font-size: 10.91px;">Nginx学习</a> <a href="/tags/NoSQL学习/" style="font-size: 16.36px;">NoSQL学习</a> <a href="/tags/Python学习/" style="font-size: 20px;">Python学习</a> <a href="/tags/Web前端/" style="font-size: 14.55px;">Web前端</a> <a href="/tags/大数据/" style="font-size: 12.73px;">大数据</a> <a href="/tags/安全测试/" style="font-size: 10px;">安全测试</a> <a href="/tags/性能测试/" style="font-size: 14.55px;">性能测试</a> <a href="/tags/爬虫学习/" style="font-size: 15.45px;">爬虫学习</a> <a href="/tags/网络基础知识/" style="font-size: 10px;">网络基础知识</a> <a href="/tags/自动化测试/" style="font-size: 13.64px;">自动化测试</a> <a href="/tags/软件工具/" style="font-size: 12.73px;">软件工具</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">46</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">8</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/02/22/centos7-4鲁班部署/">centos7.4鲁班部署</a>
          </li>
        
          <li>
            <a href="/2020/02/14/Centos7查看、新增和删除端口/">Centos7查看、新增和删除端口</a>
          </li>
        
          <li>
            <a href="/2020/02/07/centos7查看、打开和关闭防火墙/">centos7查看、打开和关闭防火墙</a>
          </li>
        
          <li>
            <a href="/2020/02/07/使用netstat、ss、lsof命令查询服务端口/">使用netstat、ss、lsof命令查询服务端口</a>
          </li>
        
          <li>
            <a href="/2019/12/22/已经安装nginx情况下添加http-ssl-module模块/">已经安装nginx情况下添加http_ssl_module模块</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">About</h3>
    <div class="widget">
       Email:<a>liuyongqian51@163.com</a><br />
          QQ:<a>272501447</a><br />
	  Github:<a></a>
    </div>
  </div>

  
  

</aside>


        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 刘永前<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>

</footer>


    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>