<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>LiuYongQian</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="永远相信美好的事情将要发生！">
<meta property="og:type" content="website">
<meta property="og:title" content="LiuYongQian">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="LiuYongQian">
<meta property="og:description" content="永远相信美好的事情将要发生！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LiuYongQian">
<meta name="twitter:description" content="永远相信美好的事情将要发生！">
  
    <link rel="alternate" href="/atom.xml" title="LiuYongQian" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiuYongQian</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">永远相信美好的事情将要发生！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-vi-vim" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/vi-vim/" class="article-date">
  <time datetime="2018-03-28T14:55:30.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/vi-vim/">vi/vim</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>vi/vim</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>vi是一款用来创建编辑文件的文本编辑软件</li>
<li>vi的三大模式：<ul>
<li>命令模式：用户刚刚启动 vi，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符</li>
<li>底线命令模式：在命令模式下按下:（英文冒号）就进入了底线命令模式，主要进行文件的保存和退出</li>
<li>编辑模式：在命令模式下按下i就进入了编辑模式</li>
</ul>
</li>
<li>模式之间的转化常用到Esc，Shift+：</li>
</ul>
<p></p><h6>命令模式</h6><p></p>
<ul>
<li><p>常用命令</p>
<pre><code>i 切换到编辑模式，以输入字符；在当前光标处插入
a 在当前光标处下一个字符插入
o 在当前光标处下一行插入新的一行
</code></pre></li>
</ul>
<p></p><h6>底线命令行模式</h6><p></p>
<ul>
<li><p>常用命令</p>
<pre><code>:q       #表示不保存退出
:q!         #强制退出
:w         #保存修改内容
:wq         #保存并退出
:set nu  #显示行号
:set nonu   #不显示行号
:r 文件名    #在编辑的数据中，读入另一个档案的数据，将文件内容加到游标所在行后面
:1,$s /word1/word2/g  #从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 
:n1,n2s/word1/word2/g #n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2
</code></pre></li>
</ul>
<p></p><h6>编辑模式</h6><p></p>
<ul>
<li><p>删除、复制、粘贴</p>
<pre><code>gg  移到这个文件的第一行
G   移到这个文件的最后一行
ngg 移到这个文件的第几行

yy     复制光标所在行
nyy 复制光标所在的向下n行

P  大写，粘贴在光标的上一行
p  小写，粘贴在光标的下一行

dd        删除光标所在一整行
ndd        删除光标所在向下n行

数字0    移到这一行的最前面
$         移到这一行的最后面

u        撤销上一次的操作
Ctrl+r    恢复撤销
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/vi-vim/" data-id="cjtyfrvv200540owvhbboj34m" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-linux常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/linux常用命令/" class="article-date">
  <time datetime="2018-03-28T09:05:54.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/linux常用命令/">linux常用命令</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>linux常用命令</h5><p></p>
<hr>
<hr>
<p></p><h6>常见的系统目录结构</h6><p></p>
<ul>
<li><p>根目录下</p>
<pre><code>[root@localhost ~]# ls /
bin   dev  ftp   lib    media  opt   root  sbin  sys  usr
boot  etc  home  lib64  mnt    proc  run   srv   tmp  var
</code></pre><ul>
<li>bin：Binary的缩写, 这个目录存放着最经常使用的命令</li>
<li>boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件</li>
<li>dev：Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的</li>
<li>etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录</li>
<li>home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的</li>
<li>lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库</li>
<li>media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下</li>
<li>mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了</li>
<li>opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的</li>
<li>proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息</li>
<li>root：该目录为系统管理员，也称作超级权限者的用户主目录</li>
<li>tmp：这个目录是用来存放一些临时文件的</li>
<li>usr：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录</li>
<li>var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件</li>
</ul>
</li>
</ul>
<p></p><h6>终端</h6><p></p>
<ul>
<li><p>用户</p>
<pre><code>新建用户：useradd &lt;name&gt;  系统自动在/home下创建与此用户同名的文件夹
         passwd &lt;name&gt;
删除用户：userdel &lt;name&gt;
切换用户：su &lt;name&gt;
退出当前用户：logout (普通用户)
             exit  （管理用户）
</code></pre></li>
<li><p>前缀</p>
<pre><code>[root@localhost ~]# 

1.root 表示登录的用户名
2.localhost 表示登录的主机，服务器地址
3.~ 表示当前用户的所在路径，即/root；主目录，当前用户的主目录
4.# 表示超管用户，$ 表示普通用户
</code></pre></li>
<li><p>开机关机<br>不管是重启系统还是关闭系统，首先要运行sync命令，把内存中的数据写到磁盘中</p>
<pre><code>sync 将数据由内存同步到硬盘中
shutdown -h now 离开关机
shutdown -h +10 10分钟后关机
shutdown -h 10:10 系统会在今天的10:10关机
reboot 系统重启
halt 关闭系统
</code></pre></li>
</ul>
<p></p><h6>目录/文件命令</h6><p></p>
<ul>
<li><p>新建目录</p>
<pre><code>mkdir &lt;目录名&gt;                        创建单个目录
mkdir -p &lt;目录名1&gt;/&lt;目录名2&gt;/&lt;目录名3&gt; 创建多层目录
mkdir -m *** &lt;目录名&gt;                 创建目录时指定权限，三颗星代表rwx的数字码
</code></pre></li>
<li><p>新建文件</p>
<pre><code>touch 文件名
</code></pre></li>
<li><p>删除目录</p>
<pre><code>rmdir &lt;目录名&gt;        删除空的目录
rm -r &lt;目录名&gt;        递归删除整个目录树,非空
rm &lt;文件名或者目录名&gt;        删除文件
rm -i &lt;文件名或者目录名&gt;     互动模式，在删除前会询问是否动作
rm -f &lt;文件名&gt;        强制删除文件，没有提示
</code></pre></li>
<li><p>查看目录</p>
<pre><code>ls 表示查看当前目录下的文件或者文件夹
ls -a 表示查看当前目录下的所有内容，包括隐藏文件
ls -l 表示查看当前目录下内容的详细信息
ls -al 表示查看当前目录下所有内容的详细内容
</code></pre></li>
<li><p>切换目录</p>
<pre><code>cd [相对路径或绝对路径] .表示当前路径  ..表示上层路径
</code></pre></li>
<li><p>复制目录/文件</p>
<pre><code>cp 源文件 /目的地址
cp -i 源文件 /目的地址     若目标档已存在，在覆盖时会先询问动作的进行
</code></pre></li>
<li><p>剪切目录/文件</p>
<pre><code>mv 文件名/目录名 目的地
</code></pre></li>
<li><p>重命名</p>
<pre><code>mv 文件名/目录名 新的文件名/目录名
</code></pre></li>
</ul>
<p></p><h6>文件内容查看</h6><p></p>
<ul>
<li><p>cat、more、head</p>
<pre><code>cat 文件名      #正序查看，由第一行开始显示文件内容
cat -n 文件名   #连同空白行也会显示行号

tac 文件名      #倒序查看
tac -n 文件名   #连同空白行也会显示行号

more 文件名     #查看大文件，显示百分比；空白键代表向下翻页，Enter键表示向下翻行
less 文件夹     #查看大文件，不显示百分比；空白键代表向下翻页，[pgup][pgdn]代表向上向下翻页

head 文件名             #默认显示前10行
head -n 数字 文件名       #规定显示前几行

tail 文件名               #默认显示最后10行
tail -n 数字 文件名      #规定显示最后几行
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/linux常用命令/" data-id="cjtyfrvu5004o0owvlofhxxo6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-session会话" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/session会话/" class="article-date">
  <time datetime="2018-03-28T09:01:57.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/session会话/">session会话</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>session会话</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>在我们登录成功之后，我们需要把用户信息显示在页面上，并且在跳转到别的页面的时候，这个用户依然是已经登录的状态浏览器可以识别，这就需要session 会话作用域</li>
<li>django session的设计原理<ul>
<li>a、如果用户是第一次请求（就看客户端ie是否保存了sessionId的cookie）<br>创建session model <br>生成一个key sessionId 随机的一个字符串（uuid使id永远也不会重复）<br>保存到你session_engine指定位置<br>保存到cookie中，在客户的浏览器中</li>
<li>b、如果第二次以上的请求，客户端ie都会自动提交cookie到django中，django中利用你配置的SessionMiddleware中间件激活session利用cookie中的sessionID到session_engine指定位置读取session model，并设置到request的session属性上<br>正是因为这样才能在view里面通过request.session使用session</li>
<li>session只能储存json也就是字典类型的数据; session本身就是一个dict字段;session在存数据时数据必须支持序列化json</li>
</ul>
</li>
</ul>
<p></p><h6>步骤</h6><p></p>
<ul>
<li><p>1.installed_apps</p>
<pre><code>#settings.py
INSTALLED_APPS = [
    &apos;django.contrib.sessions&apos;,
]
</code></pre></li>
<li><p>2.中间件（帮我们启用session）</p>
<pre><code>#settings.py
MIDDLEWARE = [
   &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,
]
</code></pre></li>
<li><p>3.设置存储形式（储存在设置数据库中）</p>
<pre><code>makemigrations sessions
migrate
</code></pre></li>
<li><p>4.引用 request.session</p>
<pre><code>#views.py
def login(request):
    if request.method==&quot;GET&quot;:
        return render(request,&apos;login.html&apos;,{})
    else:
        username=request.POST.get(&apos;username&apos;)
        pwd=request.POST.get(&apos;pwd&apos;)
        BlogUserSet = BlogUser.objects.filter(username=username,pwd=pwd)
        if len(BlogUserSet)==1:
            session=request.session
            session[&apos;user&apos;]={&apos;username&apos;:BlogUserSet.first().username}
            return redirect(reverse(&apos;user:welcome&apos;))
            #return redirect(reverse(&apos;user:welcome&apos;,args=[BlogUserSet.first().id]))
        else:
            return render(request,&apos;login.html&apos;,{&apos;username&apos;:username,&apos;error&apos;:&apos;用户名或者密码错误！&apos;})
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/session会话/" data-id="cjtyfrvuv00500owvzobjv1fj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-转发与重定向" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/27/转发与重定向/" class="article-date">
  <time datetime="2018-03-27T03:50:35.000Z" itemprop="datePublished">2018-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/27/转发与重定向/">转发与重定向</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>转发与重定向</h5><p></p>
<hr>
<hr>
<p></p><h6>重定向</h6><p></p>
<ul>
<li>数据库虽然已经添加了数据，但如果继续刷新浏览器数据库会保存重复的数据,这就需要重定向</li>
<li>转发：一次请求和响应，请求的地址没有发生变化，请求的数据被服务器内部的资源共享，如果此时刷新页面就会出现重做现象（服务器响应给客户的是转发）</li>
<li>重定向：一次以上的请求和响应，请求地址发生一次以上的变化。如果此时刷新页面不会出现重做现象（指向虚拟的网址页面）</li>
<li><p>需要在views.py里面导入redirect和reverse模块，然后需要在我们刷新的时候跳转到另一个页面,代码如下：</p>
<pre><code>#在bloguser/urls.py添加路径
app_name=&apos;user&apos;
urlpatterns = [
    path(&apos;register&apos;, register),
    path(&apos;welcome/&lt;int:id&gt;&apos;, welcome,name=&apos;welcome&apos;),
]

#在bloguser/views.py
def register(request):
    if request.method==&apos;GET&apos;:
        return render(request,&apos;register.html&apos;)
    elif request.method==&apos;POST&apos;:
        bloguser=BlogUser()
        bloguser.username=request.POST.get(&apos;username&apos;)
        bloguser.pwd=request.POST.get(&apos;pwd&apos;)
        bloguser.save()
        return redirect(reverse(&apos;user:welcome&apos;,args=[bloguser.id]))   #user,虚拟的命名空间，welcome，执行的函数,
def welcome(request,id):
    bloguser=BlogUser.objects.get(pk=id)
    return render(request, &apos;welcome.html&apos;, {&apos;bloguser&apos;: bloguser})

#在pyblog/urls.py下
urlpatterns = [
    path(&apos;admin/&apos;, admin.site.urls),
    path(&apos;bloguser/&apos;,include(&apos;bloguser.urls&apos;)),
    path(&apos;user/&apos;,include(&apos;bloguser.urls&apos;,namespace=&apos;user&apos;)),
]
</code></pre></li>
</ul>
<p></p><h6>重名</h6><p></p>
<ul>
<li>如果使用<code>unique=True</code>，我们必须点击提交才会告诉我们用户名重复，应该在我们输入密码的时候就告诉我们用户名重复</li>
<li><p>这时候我们需要使用ajax(ajax: jquery 是一种静态资源),不需要我们提交，当我们输入密码的时候就可以告诉我们用户名已重复</p>
<ul>
<li>1.在pyblog里面创建一个static的文件夹，接着创建js的文件夹，把jquery-3.3.1放进去</li>
<li><p>2.接着需要在setings.py里面添加static文件</p>
<pre><code>STATIC_URL = &apos;/static/&apos;
STATICFILES_DIRS=[
    os.path.join(BASE_DIR,  &apos;static&apos;)
]
</code></pre></li>
<li><p>3.在register.html中加上javascript</p>
<pre><code>&lt;script type=&quot;text/javascript&quot; src=&quot;/static/js/jquery-3.3.1.js&quot;&gt;&lt;/script&gt;
&lt;script &gt;
    $(function(){
        $(&apos;input[name=&quot;username&quot;]&apos;).blur(function(){
            uname=$(&apos;input[name=&quot;username&quot;]&apos;).val()
            CSRF=$(&quot;input[name=&apos;csrfmiddlewaretoken&apos;]&quot;).val()
            $.ajax({
                url:&apos;/bloguser/getUser&apos;,
                data:{&apos;uname&apos;:uname,&apos;csrfmiddlewaretoken&apos;:CSRF},
                type:&apos;POST&apos;,
                success:function(dat){
                    if(dat==&apos;True&apos;){
                        $(&apos;span&apos;).html(&apos;用户名已经存在！&apos;)
                    }
                    else{
                        $(&apos;span&apos;).html(&apos;用户名可以使用！&apos;)
                    }
                }
            })
        })
    })
&lt;/script&gt;
</code></pre></li>
<li><p>4.在views.py定义一个getUser(),同时需要导入HttpResponse模块，用来判断用户名有没有重复</p>
<pre><code>def getUser(request):
    uname=request.POST.get(&apos;uname&apos;)
    BlogUserSet=BlogUser.objects.filter(username=uname)
    if len(BlogUserSet)==1:
        return HttpResponse(&apos;True&apos;)
    else:
        return HttpResponse(&apos;False&apos;)
</code></pre></li>
<li><p>5.然后在bloguser\urls.py配置一下路径</p>
<pre><code>app_name=&apos;user&apos;
urlpatterns = [
    path(&apos;register&apos;, register),
    path(&apos;getUser&apos;, getUser),
    path(&apos;welcome/&lt;int:id&gt;&apos;, welcome,name=&apos;welcome&apos;),
]
</code></pre></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/27/转发与重定向/" data-id="cjtyfrvzm007r0owvwy3qernd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-pyspider框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/24/pyspider框架/" class="article-date">
  <time datetime="2018-03-24T10:41:19.000Z" itemprop="datePublished">2018-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/24/pyspider框架/">pyspider框架</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>pyspider框架</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>pyspider 是一个用python实现的功能强大的网络爬虫系统，能在浏览器界面上进行脚本的编写，功能的调度和爬取结果的实时查看，后端使用常用的数据库进行爬取结果的存储，还能定时设置任务与任务优先级等</li>
<li>PhantomJS 是一个基于 WebKit 的服务器端 JavaScript API。它全面支持web而不需浏览器支持，其快速、原生支持各种Web标准：DOM 处理、CSS 选择器、JSON、Canvas 和 SVG。 PhantomJS 可以用于页面自动化、网络监测、网页截屏以及无界面测试等</li>
<li>安装完pyspider、phantomJS后，在命令行输入<code>pyspider all</code>启动pyspider所有服务组件…然后浏览器访问 <a href="http://localhost:5000，如果正常出现" target="_blank" rel="noopener">http://localhost:5000，如果正常出现</a> PySpider 的页面，那证明一切OK</li>
<li>pyspider的架构主要分为 scheduler（调度器）, fetcher（抓取器）, processor（脚本执行）,以及一个监控组件，当启动服务组件的时候，这些程序均开始运行了…<ul>
<li>1.各个组件间使用消息队列连接，除了scheduler是单点的，fetcher 和 processor 都是可以多实例分布式部署的。 scheduler 负责整体的调度控制</li>
<li>2.任务由 scheduler 发起调度，fetcher 抓取网页内容， processor 执行预先编写的python脚本，输出结果或产生新的提链任务（发往 scheduler），形成闭环</li>
<li>3.每个脚本可以灵活使用各种python库对页面进行解析，使用框架API控制下一步抓取动作，通过设置回调控制解析动作</li>
</ul>
</li>
</ul>
<p></p><h6>页面内容解析</h6><p></p>
<ul>
<li>拿www.reeoo.com这个网页，爬取上面的数据</li>
<li>创建新项目页面：<ul>
<li>Project Name：任务的名字</li>
<li>Start URL(s)：爬取任务开始的地址</li>
</ul>
</li>
<li><p>创建后的页面</p>
<pre><code>from pyspider.libs.base_handler import *
class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    #@every(minutes=24 * 60) 通知 scheduler（框架的模块） 每天运行一次
    def on_start(self):
    #on_start(self) 程序的入口，当点击左侧绿色区域右上角的 run 按钮时首先会调用这个函数
        self.crawl(&apos;https://reeoo.com/&apos;, callback=self.index_page)
    #self.crawl(url, callback) pyspider库主要的API，用于创建一个爬取任务，url 为目标地址，这里为我们刚刚创建任务指定的起始地址，callback 为抓取到数据后的回调函数

    @config(age=10 * 24 * 60 * 60)
    #@config(age=10 * 24 * 60 * 60) 设置任务的有效期限，在这个期限内目标爬取的网页被认为不会进行修改
    def index_page(self, response):
    #index_page(self, response) 参数为 Response 对象，response.doc 为 pyquery 对象，主要用来方便地抓取返回的html文档中对应标签的数据
        for each in response.doc(&apos;a[href^=&quot;http&quot;]&apos;).items():
            self.crawl(each.attr.href, callback=self.detail_page)

    @config(priority=2)
    #@config(priority=2) 设定任务优先级
    def detail_page(self, response):
    #detail_page(self, response) 返回一个 dict 对象作为结果，结果会自动保存到默认的 resultdb 中，也可以通过重载方法来将结果数据存储到指定的数据库
        return {
            &quot;url&quot;: response.url,
            &quot;title&quot;: response.doc(&apos;title&apos;).text(),
        }
</code></pre></li>
<li><p>运行代码后时出现 HTTP 599: SSL certificate problem: unable to get local issuer certificate错误时：<br><br>使用 self.crawl(url, callback=self.index_page, validate_cert=False)</p>
</li>
<li>运行<br>1.点击左边绿色区域右上角的 run 按钮，运行之后页面下册的 follows 按钮出现红色角标<br>2.选中 follows 按钮，看到 index_page 行，点击行右侧的运行按钮<br>3.运行完成后显示 www.reeoo.com 页面上所有的url<br>4.此时任意选择一个结果运行，此时调用的是 detail_page 方法，返回结果为json格式的数据，这里我们保存的是网页的 title 和 url，见左侧黑色的区域<br>5.回到主页面，此时看到任务列表显示刚刚创建的任务，设置 status 为 running，然后点击 Run 按钮执行<br>6.执行过程中可以看到整个过程的打印输出<br>7.执行完成后，点击 Results 按钮，进入到爬取结果的页面<br>8.右上方的按钮选择将结果数据保存成对应的格式，例如：JSON格式的数据</li>
</ul>
<p></p><h6>查找文件路径</h6><p></p>
<ul>
<li>由于配置了windows的环境变量，所以习惯性的打开CMD后就直接敲命令行执行 pyspider语句，但找不到pyspider存储的数据在哪里</li>
<li>后来才发现，pyspider命令行执行的时候，数据库data文件会自动在当前目录生成，即在<code>C:\Users\DELL&gt;</code>下，<code>C:\Users\DELL\data</code></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/24/pyspider框架/" data-id="cjtyfrvtd004a0owv5w2aost5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-selenium模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/selenium模块/" class="article-date">
  <time datetime="2018-03-23T15:15:47.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/selenium模块/">selenium模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>selenium模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>selenium 是一套完整的web应用程序测试系统，Selenium的核心Selenium Core基于JsUnit，完全由JavaScript编写，因此可以用于任何支持JavaScript的浏览器上，爬虫中主要用来解决JavaScript渲染问题</li>
<li>Selenium.Webdriver支持的浏览器中，比较重要的PhantomJS,PhantomJS是一个基于WebKit的服务端JavaScript API,支持Web而不需要浏览器支持，其快速、原生支持各种Web标准：Dom处理，CSS选择器，JSON等等。PhantomJS可用于页面自动化、网络监测、网页截屏，以及无界面测试</li>
</ul>
<p></p><h6>查找元素</h6><p></p>
<ul>
<li><p>单个元素和多个元素的查找，用法基本一致</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By
from time import sleep

browser=webdriver.Chrome()
browser.get(&apos;http://www.baidu.com&apos;)  #声明浏览器对象
#print(browser.page_source)       #打印百度首页的源代码
input=browser.find_element(By.ID,&apos;kw&apos;)
input.clear()
input.send_keys(&apos;selenium&apos;)
button=browser.find_element(By.CSS_SELECTOR,&apos;#su&apos;)
button.click()
sleep(3)
browser.close()
</code></pre></li>
<li><p>这里列举一下常用的查找元素方法：</p>
<pre><code>find_element_by_name
find_element_by_id
find_element_by_xpath
find_element_by_link_text
find_element_by_partial_link_text
find_element_by_tag_name
find_element_by_class_name
find_element_by_css_selector
</code></pre></li>
</ul>
<p></p><h6>执行JavaScript</h6><p></p>
<ul>
<li><p>这是一个非常有用的方法，这里就可以直接调用js方法来实现一些操作，下面的例子是通过登录知乎然后通过js翻到页面底部，并弹框提示</p>
<pre><code>from selenium import webdriver

browser=webdriver.Chrome()
browser.get(&apos;http://www.zhihu.com/explore&apos;)  #声明浏览器对象
browser.execute_script(&apos;window.scrollTo(0,document.body.scrollHeight)&apos;)
browser.execute_script(&apos;alert(&quot;Hello World!&quot;)&apos;)
</code></pre></li>
</ul>
<p></p><h6>01</h6><p></p>
<ul>
<li><p>获取属性值、文本值</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By

browser=webdriver.Chrome()
browser.get(&apos;https://www.zhihu.com/explore&apos;)
logo=browser.find_element(By.ID,&apos;zh-top-link-logo&apos;)
print(logo.get_attribute(&apos;class&apos;))    #获取元素的属性值
print(logo.text)                      #获取文本值
print(logo.id)
print(logo.location)                  #获取位置
print(logo.tag_name)                  #获取标签名
print(logo.size)
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/selenium模块/" data-id="cjtyfrvue004s0owv8h75plye" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-pyquery模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/pyquery模块/" class="article-date">
  <time datetime="2018-03-23T15:15:27.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/pyquery模块/">pyquery模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>pyquery模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>PyQuery库也是一个非常强大又灵活的网页解析库，是 Python 仿照 jQuery 的严格实现</li>
<li><p>初始化<br>初始化的时候一般有三种传入方式：传入字符串，传入url,传入文件</p>
<pre><code>from pyquery import PyQuery as pq
html=&apos;&apos;&apos;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
             &lt;p&gt;This is a paragraph.&lt;/p&gt;        
        &lt;/ul&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
###字符串初始化
doc=pq(html)      #doc其实就是一个pyquery对象
print(doc(&apos;li&apos;))  #doc(标签名)就可以获取所有的该标签的内容
print(doc(&apos;.item-0&apos;))  #doc(&apos;.class_name&apos;)，doc(&apos;#id_name&apos;)
###URL初始化
url=&apos;http://www.baidu.com&apos;
doc=pq(url,encoding=&apos;utf-8&apos;)
print(doc(&apos;head&apos;))
###文件初始化
在pq()这里可以传入url参数也可以传入文件参数，当然这里的文件通常是一个html文件，例如：pq(filename=&apos;index.html&apos;)
</code></pre></li>
</ul>
<p></p><h6>查找元素</h6><p></p>
<ul>
<li><p>子元素（children,find）</p>
<pre><code>doc=pq(html)
items=doc(&apos;.list&apos;)
lis=items.find(&apos;li&apos;)   #lis=items.children()可以实现同样的效果
print(lis)
</code></pre></li>
<li><p>父元素（parent,parents）</p>
<pre><code>doc=pq(html)
items=doc(&apos;.list&apos;)
cont=items.parent() #可以找到父元素的所有内容
#cont=items.parents()返回两部分内容，一个是父节点信息，一个是父节点的父节点的信息即祖先节点的信息
print(cont)
</code></pre></li>
<li><p>兄弟元素（siblings）</p>
<pre><code>doc=pq(html)
li=doc(&apos;.list .item-0.active&apos;)
print(li.siblings())
</code></pre></li>
<li><p>遍历</p>
<pre><code>doc=pq(html)
lis=doc(&apos;li&apos;).items()
print(type(lis))     #&lt;class &apos;generator&apos;&gt;
for li in lis:
    print(li)        #通过for循环得到的每个元素依然是一个pyquery对象
</code></pre></li>
</ul>
<p></p><h6>获取信息</h6><p></p>
<ul>
<li><p>获取属性值–pyquery对象.attr(属性名)</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-1 a&apos;)
print(a.attr(&apos;href&apos;))
</code></pre></li>
<li><p>获取文本–pyquery对象.text()</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-0.active a&apos;)
print(a.text())
</code></pre></li>
<li><p>获取html–puquery对象.html()获取当前标签所包含的html信息</p>
<pre><code>doc=pq(html)
a=doc(&apos;.list .item-0.active a&apos;)
print(a.html())
</code></pre></li>
</ul>
<p></p><h6>DOM操作</h6><p></p>
<ul>
<li><p>addClass、removeClass添加和删除属性值</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.addClass(&apos;2018&apos;)
ul.removeClass(&apos;2018&apos;)
print(ul)
</code></pre></li>
<li><p>attr,css给标签添加和修改属性</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.attr(&apos;id&apos;,&apos;201803&apos;)
ul.css(&apos;font-size&apos;,&apos;15px&apos;)
print(ul)         #&lt;ul class=&quot;list&quot; id=&quot;201803&quot; style=&quot;font-size: 15px&quot;&gt;
</code></pre></li>
<li><p>remove将无用的或者干扰的标签直接删除</p>
<pre><code>doc=pq(html)
ul=doc(&apos;.list&apos;)
ul.find(&apos;p&apos;).remove()
print(ul.text())
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/pyquery模块/" data-id="cjtyfrvto004g0owvbvoovhm4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-beautifulsoup模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/23/beautifulsoup模块/" class="article-date">
  <time datetime="2018-03-23T10:31:34.000Z" itemprop="datePublished">2018-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/23/beautifulsoup模块/">beautifulsoup模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>beautifulsoup模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>BeautifulSoup是Python的一个库，最主要的功能就是从网页爬取我们需要的数据。BeautifulSoup将html解析为对象进行处理，全部页面转变为字典或者数组，相对于正则表达式的方式，可以大大简化处理过程</li>
<li>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装</li>
<li><p>以下是这两个库的比较：</p>
<pre><code>1.Python标准库    BeautifulSoup(html,’html.parser’)    
Python内置标准库；执行速度快     容错能力较差
2.lxml HTML解析库    BeautifulSoup(html,’lxml’)    
速度快；容错能力强    需要安装，需要C语言库
</code></pre></li>
</ul>
<p></p><h6>标签选择器</h6><p></p>
<ul>
<li><p>soup.标签名，可以获得这个标签的内容；通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;html&gt;
        &lt;head&gt;
            &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;
        &lt;/head&gt;
        &lt;body&gt;
            &lt;p class=&quot;story&quot;&gt;
                Once upon a time there were three little sisters; and their names were
                &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                    &lt;span&gt;Elsie&lt;/span&gt;
                &lt;/a&gt;
                &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;
                and
                &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
                and they lived at the bottom of a well.
            &lt;/p&gt;
            &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)    #创建对象
print(soup.head.title.string)
</code></pre></li>
<li><p>基本用法</p>
<pre><code>soup.prettify()，自动补全缺失的标签
soup.标签名，可以获得这个标签的内容
soup.标签名.name，可以获得该标签的名称
soup.标签名[&apos;name&apos;]，可以获得该标签的name属性值
soup.标签名.string，可以获取第一个该标签的内容
soup.标签名.内标签名.string，嵌套方式
soup.标签名.contents，将该标签下的所有子标签存入到一个列表中
soup.标签名.parent，可以获取父节点所有信息
soup.标签名.next_sibling 获取下一个兄弟标签
soup.标签名.next_siblings 获取后面的兄弟节点
souo.标签名.previous_sinbling 获取上一个兄弟标签
soup.标签名.previous_siblings 获取前面的兄弟节点
</code></pre></li>
</ul>
<p></p><h6>标准选择器</h6><p></p>
<ul>
<li>soup.find_all(name,attrs,text)可根据标签名、属性、内容查找文档</li>
<li><p>soup.find(name,attrs,text)返回匹配结果的第一个元素</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;div class=&quot;panel&quot;&gt;
        &lt;div class=&quot;panel-heading&quot;&gt;
            &lt;h4&gt;Hello&lt;/h4&gt;
        &lt;/div&gt;
        &lt;div class=&quot;panel-body&quot;&gt;
            &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
            &lt;/ul&gt;
            &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)
for li in soup.find_all(&apos;ul&apos;):    #以针对结果再次find_all,从而获取所有的li标签信息
    print(li.find_all(&apos;li&apos;))
print(soup.find_all(attrs={&apos;class_&apos;:&apos;element&apos;}))
#attrs可以传入字典的方式来查找标签，但是这里有个特殊的就是class,因为class在python中是特殊的字段，所以如果想要查找class相关的可以更改attrs={&apos;class_&apos;:&apos;element&apos;}
</code></pre></li>
<li><p>基本用法：</p>
<pre><code>soup.find_all(&apos;标签名&apos;)  结果返回的是一个列表的方式
soup.finf_all(attrs={&apos;class_&apos;:&apos;element&apos;})
soup.find_all(text=&apos;Foo&apos;) 返回的是查到的所有的text=&apos;Foo&apos;的文本
</code></pre></li>
</ul>
<p></p><h6>CSS选择器</h6><p></p>
<ul>
<li>通过select()直接传入CSS选择器就可以完成选择</li>
<li>通过get_text()可以获取文本内容</li>
<li><p>通过 标签名[属性名] 或者 标签名.attrs[属性名]获取属性</p>
<pre><code>from bs4 import BeautifulSoup
html=&apos;&apos;&apos;
    &lt;div class=&quot;panel&quot;&gt;
        &lt;div class=&quot;panel-heading&quot;&gt;
            &lt;h4&gt;Hello&lt;/h4&gt;
        &lt;/div&gt;
        &lt;div class=&quot;panel-body&quot;&gt;
            &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
            &lt;/ul&gt;
            &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
                &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
                &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&apos;&apos;&apos;
soup=BeautifulSoup(html,&apos;lxml&apos;)
print(soup.select(&apos;#list-2 .element&apos;))
print(soup.ul[&apos;id&apos;])
for li in soup.select(&apos;li&apos;):
    print(li.get_text())     #获得文本内容
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/23/beautifulsoup模块/" data-id="cjtyfrvsa003q0owvjstxwam6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-mongodb排序" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/22/mongodb排序/" class="article-date">
  <time datetime="2018-03-22T10:47:37.000Z" itemprop="datePublished">2018-03-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/22/mongodb排序/">mongodb排序</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>mongodb排序</h5><p></p>
<hr>
<hr>
<p></p><h6>排序<h6><p></p>
<ul>
<li>sort()方法对数据进行排序，sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列</li>
<li><p>语法：db.COLLECTION_NAME.find().sort({KEY:1})</p>
<pre><code># 插入数据库的数据如下：
{
    title: &quot;PHP 教程&quot;, 
    description: &quot;PHP 是一种创建动态交互性站点的强有力的服务器端脚本语言。&quot;, 
    by: &quot;菜鸟教程&quot;, 
    url: &quot;http://www.runoob.com&quot;, 
    tags: [ &quot;php&quot; ], 
    likes: 200 
}
{  
    title: &quot;Java 教程&quot;, 
    description: &quot;Java 是由Sun Microsystems公司于1995年5月推出的高级程序设计语言。&quot;, 
    by: &quot;菜鸟教程&quot;, 
    url: &quot;http://www.runoob.com&quot;, 
    tags: [ &quot;java&quot; ], 
    likes: 150 
}
{   title: &quot;MongoDB 教程&quot;, 
    description: &quot;MongoDB 是一个 Nosql 数据库&quot;, 
    by: &quot;菜鸟教程&quot;, 
    url: &quot;http://www.runoob.com&quot;, 
    tags: [ &quot;mongodb&quot; ], 
    likes : 100 
}

》》db.getCollection(&apos;teacher&apos;).find({},{&apos;title&apos;:1,_id:0}).sort({&apos;likes&apos;:1})
/* 1 */
{
    &quot;title&quot; : &quot;MongoDB 教程&quot;
}
/* 2 */
{
    &quot;title&quot; : &quot;Java 教程&quot;
}
/* 3 */
{
    &quot;title&quot; : &quot;PHP 教程&quot;
}
</code></pre></li>
</ul>
<p></p><h6>Limit</h6><p></p>
<ul>
<li>需要在MongoDB中读取指定数量的数据记录，可以使用MongoDB的Limit方法</li>
<li>limit()方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数</li>
<li><p>语法为：db.COLLECTION_NAME.find().limit(NUMBER)</p>
<pre><code>》》db.getCollection(&apos;teacher&apos;).find({},{&apos;title&apos;:1,_id:0}).limit(2)
/* 1 */
{
    &quot;title&quot; : &quot;PHP 教程&quot;
}
/* 2 */
{
    &quot;title&quot; : &quot;Java 教程&quot;
}
</code></pre></li>
</ul>
<p></p><h6>Skip</h6><p></p>
<ul>
<li>使用skip()方法来跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数</li>
<li><p>语法：db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)</p>
<pre><code>》》db.getCollection(&apos;teacher&apos;).find({},{&apos;title&apos;:1,_id:0}).limit(1).skip(1)
/* 1 */
{
    &quot;title&quot; : &quot;Java 教程&quot;
}
</code></pre></li>
<li><p>sort(), limilt(),skip() 三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()</p>
</li>
</ul>
</h6></h6>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/22/mongodb排序/" data-id="cjtyfrvtg004c0owvs7jed647" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MongoDB数据库/">MongoDB数据库</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-requests模块" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/22/requests模块/" class="article-date">
  <time datetime="2018-03-22T07:28:23.000Z" itemprop="datePublished">2018-03-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/22/requests模块/">requests模块</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>requests模块</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li><p>Requests是用python语言基于urllib编写的，采用的是Apache2 Licensed开源协议的HTTP库，Requests它会比urllib更加方便，可以节约我们大量的工作</p>
<pre><code>import requests
res=requests.get(&apos;https://www.baidu.com&apos;)
print(res.status_code)      #返回状态码
print(res.headers)      #打印请求网址的headers所有信息
print(res.cookies)      #打印请求网址的cookies信息
for key,value in res.cookies.items():
    print(key,&apos;==&apos;,value)
print(res.text)          #res.text返回的是Unicode格式，通常需要转换为utf-8格式，否则就是乱码
res.encoding=&apos;utf-8&apos;
print(res.text)

print(res.content)     #res.content是二进制模式，可下载视频之类的，如想看的话需要decode成utf-8格式
print(res.content.decode(&apos;utf-8&apos;))

#如果你想取文本，可以通过res.text;如果想取图片，文件，则可以通过res.content
</code></pre></li>
</ul>
<p></p><h6>GET请求</h6><p></p>
<ul>
<li><p>带参数的GET请求,如果想查询<a href="http://httpbin.org/get页面的具体参数，需要在url里面加上" target="_blank" rel="noopener">http://httpbin.org/get页面的具体参数，需要在url里面加上</a></p>
<pre><code>import requests
url = &apos;http://httpbin.org/get&apos;
data = {&apos;name&apos;:&apos;zhangsan&apos;,&apos;age&apos;:&apos;25&apos;}
res=requests.get(url,params=data)
print(res.url)                #result:http://httpbin.org/get?age=25&amp;name=zhangsan
res.encoding=&apos;utf-8&apos;
print(res.text)
</code></pre></li>
</ul>
<p></p><h6>Json数据</h6><p></p>
<ul>
<li><p>requests中res.json()方法等同于json.loads（res.text）方法</p>
<pre><code>import requests,json
url = &apos;http://httpbin.org/get&apos;
res=requests.get(url)
print(res.json())
print(json.loads(res.text))
</code></pre></li>
</ul>
<p></p><h6>添加header</h6><p></p>
<ul>
<li><p>添加headers的目的是为了防止发生服务器内部错误，可以正常执行</p>
<pre><code>import requests
url=&apos;https://www.zhihu.com&apos;
header={
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0&quot;
}
res=requests.get(url,headers=header)
res.encoding=&apos;utf-8&apos;
print(res.status_code)
print(res.text)
</code></pre></li>
</ul>
<p></p><h6>post请求</h6><p></p>
<ul>
<li><p>通过post把数据提交到url地址，等同于一字典的形式提交form表单里面的数据</p>
<pre><code>import requests
url=&apos;http://httpbin.org/post&apos;
data = {&apos;name&apos;:&apos;jack&apos;,&apos;age&apos;:&apos;23&apos;}
header={
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0&quot;
}
res=requests.post(url,data=data,headers=header)
res.encoding=&apos;utf-8&apos;
print(res.status_code)
print(res.text)
</code></pre></li>
</ul>
<p></p><h6>高级操作</h6><p></p>
<ul>
<li><p>文件上传</p>
<pre><code>import requests
url=&quot;http://httpbin.org/post&quot;
file={&apos;files&apos;:open(&apos;test.jpg&apos;,&apos;rb&apos;)}
res=requests.post(url,files=file)
res.encoding=&apos;utf-8&apos;
print(res.text)
</code></pre></li>
<li><p>会话维持</p>
<ul>
<li><p>cookie的一个作用就是可以用于模拟登陆，做会话维持</p>
<pre><code>import requests
se = requests.session()     #声明session对象
se.get(&apos;http://httpbin.org/cookies/set/number/12456&apos;) #在一个浏览器中浏览两个页面
res= se.get(&apos;http://httpbin.org/cookies&apos;)
print(res.text)
</code></pre></li>
</ul>
</li>
<li><p>证书验证</p>
<ul>
<li><p>在请求https时，request会进行证书的验证</p>
<pre><code>import requests,urllib3
url=&apos;https://www.12306.cn&apos;
urllib3.disable_warnings()       #消除验证证书的警报
res=requests.get(url,verify=False)
#在请求https时，request会进行证书的验证，如果验证失败则会抛出异常,
#为避免这种情况发生可通过verify=False，但是这样是可以访问到页面结果,也还有警报，可消除
print(res.status_code)
</code></pre></li>
</ul>
</li>
<li><p>代理设置</p>
<ul>
<li><p>受限制网站需要使用代理服务器访问</p>
<pre><code>import requests
proxies = {
    &quot;http&quot;: &quot;http://123.206.75.213:8080&quot;,
}
response = requests.get(&quot;https://www.taobao.com&quot;, proxies=proxies)
print(response.status_code)
</code></pre></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/22/requests模块/" data-id="cjtyfrvts004i0owvmei8r507" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/5/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/7/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django学习/">Django学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA项目部署/">JAVA项目部署</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux学习/">Linux学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB数据库/">MongoDB数据库</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL学习/">MySQL学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx学习/">Nginx学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python学习/">Python学习</a><span class="tag-list-count">27</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis数据库/">Redis数据库</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web前端/">Web前端</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全测试/">安全测试</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/性能测试/">性能测试</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫学习/">爬虫学习</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络基础知识/">网络基础知识</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自动化测试/">自动化测试</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件工具/">软件工具</a><span class="tag-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Django学习/" style="font-size: 12.22px;">Django学习</a> <a href="/tags/JAVA项目部署/" style="font-size: 13.33px;">JAVA项目部署</a> <a href="/tags/Linux学习/" style="font-size: 18.89px;">Linux学习</a> <a href="/tags/MongoDB数据库/" style="font-size: 12.22px;">MongoDB数据库</a> <a href="/tags/MySQL学习/" style="font-size: 18.89px;">MySQL学习</a> <a href="/tags/Nginx学习/" style="font-size: 10px;">Nginx学习</a> <a href="/tags/Python学习/" style="font-size: 20px;">Python学习</a> <a href="/tags/Redis数据库/" style="font-size: 15.56px;">Redis数据库</a> <a href="/tags/Web前端/" style="font-size: 16.67px;">Web前端</a> <a href="/tags/大数据/" style="font-size: 13.33px;">大数据</a> <a href="/tags/安全测试/" style="font-size: 11.11px;">安全测试</a> <a href="/tags/性能测试/" style="font-size: 15.56px;">性能测试</a> <a href="/tags/爬虫学习/" style="font-size: 17.78px;">爬虫学习</a> <a href="/tags/网络基础知识/" style="font-size: 10px;">网络基础知识</a> <a href="/tags/自动化测试/" style="font-size: 12.22px;">自动化测试</a> <a href="/tags/软件工具/" style="font-size: 14.44px;">软件工具</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">46</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">11</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/01/jemkins自动化部署-后台项目构建/">jemkins自动化部署--后台项目构建</a>
          </li>
        
          <li>
            <a href="/2019/03/25/MySQL数据库读写分离/">MySQL数据库读写分离</a>
          </li>
        
          <li>
            <a href="/2019/03/25/MySQL数据库主从复制/">MySQL数据库主从复制</a>
          </li>
        
          <li>
            <a href="/2019/03/24/清理内存缓存与交换空间/">清理内存缓存与交换空间</a>
          </li>
        
          <li>
            <a href="/2019/03/23/Nginx转发SSH代理-Stream模块/">Nginx转发SSH代理-Stream模块</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">About</h3>
    <div class="widget">
       Email:<a>liuyongqian51@163.com</a><br />
          QQ:<a>272501447</a><br />
	  Github:<a></a>
    </div>
  </div>

  
  

</aside>


        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 刘永前<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>

</footer>


    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>