<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>LiuYongQian</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="永远相信美好的事情将要发生！">
<meta property="og:type" content="website">
<meta property="og:title" content="LiuYongQian">
<meta property="og:url" content="http://yoursite.com/page/5/index.html">
<meta property="og:site_name" content="LiuYongQian">
<meta property="og:description" content="永远相信美好的事情将要发生！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LiuYongQian">
<meta name="twitter:description" content="永远相信美好的事情将要发生！">
  
    <link rel="alternate" href="/atom.xml" title="LiuYongQian" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LiuYongQian</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">永远相信美好的事情将要发生！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-jdk部署" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/11/jdk部署/" class="article-date">
  <time datetime="2018-04-11T11:48:13.000Z" itemprop="datePublished">2018-04-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/11/jdk部署/">jdk部署</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>jdk部署</h5><p></p>
<hr>
<hr>
<p></p><h6>echo遍历、输出、打印</h6><p></p>
<ul>
<li><p>输出</p>
<pre><code>name=&apos;hadoop&apos;(定义变量)
echo $name（输出变量值）
</code></pre></li>
<li><p>重定向、覆盖</p>
<pre><code>touch data1.txt(里面有内容)
echo ookk &gt; data1.txt(此时文件中内容被“ookk”覆盖)
</code></pre></li>
<li><p>追加</p>
<pre><code>touch data2.txt(里面有内容)
echo ookk &gt;&gt;data2.txt(此时文件末尾追加字段“ookk”)
</code></pre></li>
</ul>
<p></p><h6>jdk部署</h6> <p></p>
<ul>
<li><p>按照课堂讲解内容整理</p>
<pre><code>1.root下新建用户useradd hadoop,并给用户hadoop设置密码passwd hadoop
2.切换到hadoop下，su hadoop之后cd /home/hadoop下，即工作区；或者使用hadoop登录，默认进入工作区
3.新建目录mkdir opt
4.将文件jdk-8u152-linux-x64.tar.gz解压到opt目录下，命令为：
tar -zvxf jdk-8u152-linux-x64.tar.gz -C /home/hadoop/opt
5.配置jdk（两种方式）
    第一种：在hadoop的主目录下，vi .bashrc后添加：
        export JAVA_HOME=/home/hadoop/opt/jdk1.8.0_152
        export PATH=$JAVA_HOME/bin:$PATH
        source ~/.bashrc刷新
    第二种：以追加的形式，hadoop用户
        cd /opt/jdk1.8.0_152下，
        设置变量java_home=`pwd`，
        echo export JAVA_HOME=$java_home &gt;&gt; ~/.bashrc
        echo export PATH=\$JAVA_HOME\/bin:\$PATH &gt;&gt; ~/.bashrc
        追加之后刷新source ~/.bashrc
6.输入java -version查看是否配置成功
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/11/jdk部署/" data-id="cjtyh7xce003ggkwvhocoac6l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-chmod" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/09/chmod/" class="article-date">
  <time datetime="2018-04-09T10:05:31.000Z" itemprop="datePublished">2018-04-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/09/chmod/">chmod</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>chmod</h5><p></p>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>chmod(Change mode) 用来将每个文件的模式更改为指定值。Linux/Unix 的档案调用权限分为三级 : 档案拥有者、群组、其他<ul>
<li>u:目录或者文件的当前的用户</li>
<li>g:目录或者文件的当前的群组</li>
<li>o:除了目录或者文件的当前用户或者群组之外的用户或者群组</li>
<li>a:所有的用户和群组</li>
</ul>
</li>
<li>Linux的文件基本上分为三个属性：可读(r)，可写(w)，可执行(x)<ul>
<li>权限对文件的重要性<ul>
<li>r (read) 4：可读取此文件的实际内容，如读取文本文件的文字内容等 </li>
<li>w (write) 2：可以编辑、新增或者是修改该文件的内容(但不含删除该文件)</li>
<li>x (execute) 1：该文件具有可以被系统执行的权限。linux下文件是否可以执行和扩展名无关</li>
</ul>
</li>
<li>权限对目录的重要性<ul>
<li>r：表示具有读取目录结构列表的权限，可以查询该目录下的文件名数据，可以利用 ls 这个指令将该目录的内容列表显示出来</li>
<li>w：表示具有移动该目录结构列表的权限，也就是这些权限：<ul>
<li>建立新的文件与目录</li>
<li>删除已经存在的文件与目录(不论该文件的权限为何！) </li>
<li>将已存在的文件或目录进行更名</li>
<li>搬移该目录内的文件、目录位置</li>
</ul>
</li>
<li>x：目录不可以被执行，目录的x代表的是用户能否进入该目录成为工作目录的用途！ 所谓的工作目录(work directory)就是你目前所在的目录！举例来说，当你登入Linux时， 你所在的家目录就是你当下的工作目录</li>
</ul>
</li>
<li>以rwx(Owner)r-x(Group)r-x(Other)为例：这个例子表示的权限是：使用者自己可读，可写，可执行;同一组的用户可读，不可写，可执行;其它用户可读，不可写，可执行</li>
</ul>
</li>
<li>使用权限 : 所有使用者</li>
</ul>
<p></p><h6>使用</h6><p></p>
<ul>
<li>文字设定法<ul>
<li>chmod [u、g、o、a] [+（加入）、-（除去）、=（设定）] [r、w、x] [文件或者目录]</li>
</ul>
</li>
<li>数字设定法<ul>
<li>按照顺序（u）（g）（o），将权限转换成3个从0到7的八进制数字，如若要rwx属性则4+2+1=7 ; 若要rw-属性则4+2=6</li>
</ul>
</li>
</ul>
<p></p><h6>示例</h6><p></p>
<ul>
<li><p>查看权限ll</p>
<pre><code>-rw-r--r-- 1 root root 0 4月  24 15:24 backup.sh
</code></pre></li>
<li><p>将backup.sh设定为只有该档案拥有者可以执行</p>
<pre><code>chmod u+x backup.sh
</code></pre></li>
<li><p>同时修改不同用户权限</p>
<pre><code>chmod ug+w,o-x backup.sh
</code></pre></li>
<li><p>删除文件权限</p>
<pre><code>chmod a-x backup.sh
</code></pre></li>
<li><p>使用“=”设置权限</p>
<pre><code>chmod u=x backup.sh
</code></pre></li>
<li><p>根据数字修改权限</p>
<pre><code>chmod 745 backup.sh
</code></pre></li>
<li><p>将目前目录下的所有档案与子目录皆设为任何人可读取</p>
<pre><code>chmod -R a+r *
</code></pre></li>
</ul>
<p>##参考大神佳作<a href="https://www.cnblogs.com/xqzt/p/5433022.html" target="_blank" rel="noopener">每天一个linux命令:chmod</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/09/chmod/" data-id="cjtyh7xbz0036gkwv7nv23qc5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-爬虫之Mongodb常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/08/爬虫之Mongodb常用命令/" class="article-date">
  <time datetime="2018-04-08T00:16:31.000Z" itemprop="datePublished">2018-04-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/08/爬虫之Mongodb常用命令/">爬虫之Mongodb常用命令</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>爬虫之Mongodb常用命令</h5><p></p>
<hr>
<hr>
<p></p><h6>连接数据库</h6><p></p>
<ul>
<li>连接数据库，参数为空的话默认ip为localhost，端口为27017</li>
<li><p>一下三种结果都一样</p>
<pre><code>from pymongo import MongoClient
import datetime
client=MongoClient()
client=MongoClient(&apos;localhost&apos;,27017)
client=MongoClient(&apos;mongodb://localhost:27017/&apos;)  #使用url格式连接数据库
</code></pre></li>
<li><p>连接指定的数据库</p>
<pre><code>db=client.firstdb
db=client[&apos;firstdb&apos;]
</code></pre></li>
<li><p>连接指定的集合</p>
<pre><code>test1=db.student
test1=db[&apos;student&apos;]
</code></pre></li>
</ul>
<p></p><h6>插入文档</h6><p></p>
<ul>
<li><p>插入单条文档</p>
<pre><code>data1={
    &apos;name&apos;:&apos;gouzenggong&apos;,
    &apos;text&apos;:&apos;MY first blog post&apos;,
    &apos;tags&apos;:[&apos;mongo&apos;,&apos;python&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    }
test1.insert_one(data1)
</code></pre></li>
<li><p>查找单条文档</p>
<pre><code>test1.find_one()
test1.find_one({&apos;name&apos;:&apos;gouzenggong&apos;})   #指定条件查询，如果未查到，返回空

#如果指定id查询，则需要这样做
from bson.objectid import ObjectId
test1.find_one({&apos;_id&apos;:ObjectId(&apos;5ac8df4eb09c061dfc517988&apos;)})
</code></pre></li>
<li><p>插入多条文档</p>
<pre><code>data2=[
    {
    &apos;name&apos;:&apos;zhangsan&apos;,
    &apos;text&apos;:&apos;MY second blog post&apos;,
    &apos;tags&apos;:[&apos;python&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    },
    {
    &apos;name&apos;:&apos;gouzenggong&apos;,
    &apos;text&apos;:&apos;MY three blog post&apos;,
    &apos;tags&apos;:[&apos;mongo&apos;,&apos;pymongo&apos;],
    &apos;date&apos;:datetime.datetime.now()
    }
]
test1.insert_many(data2)
</code></pre></li>
<li><p>查找多条文档</p>
<pre><code>#查询所有结果
for i in test1.find():
    print(i)

#查询指定结果
for i in test1.find({&apos;name&apos;:&apos;gouzenggong&apos;}):
    print(i)

#查询总数
test1.count()

#查询指定的条数
test1.find({&apos;name&apos;:&apos;gouzenggong&apos;}).count()
</code></pre></li>
</ul>
<p></p><h6>更新文档</h6><p></p>
<ul>
<li><p>如果有找到x=1，则改成x=3，否则插入{‘x’:3}，单条</p>
<pre><code>test2=db.teacher    #连接一个新的集合
data3=[
    {&apos;x&apos;:1},{&apos;x&apos;:1},{&apos;x&apos;:1}
]
test2.insert_many(data3)

test2.update_one({&apos;x&apos;:1},{&apos;$set&apos;:{&apos;x&apos;:3}},upsert=True) #可以发现已经把其中一条改为x=3
</code></pre></li>
<li><p>如果找到x=4，则改成x=333，否则插入{‘x’:333}，单条</p>
<pre><code>#文档中是没有x=4的
test2.update_one({&apos;x&apos;:4},{&apos;$set&apos;:{&apos;x&apos;:333}},upsert=True) #可以发现新增了一条{&apos;x&apos;:333}
</code></pre></li>
<li><p>如果找到x=1，则改成x=’many’，否则插入{‘x’:’many’}，多条</p>
<pre><code>test2.update_many({&apos;x&apos;:1},{&apos;$set&apos;:{&apos;x&apos;:&apos;many&apos;}},upsert=True) #可以发现已经把所有x=1改成了x=many
</code></pre></li>
<li><p>如果找到x=4，则改成{‘x’:1,’y’；2}，否则插入{‘x’:1,’y’:2}，多条</p>
<pre><code>#文档中是没有x=4的
test2.update_many({&apos;x&apos;:4},{&apos;$set&apos;:{&apos;x&apos;:1,&apos;y&apos;:2}},upsert=True) #可以发现新增一条文档
</code></pre></li>
</ul>
<p></p><h6>小结</h6><p></p>
<ul>
<li>爬虫常用到的三条插入语句：（以test2为集合名）<ul>
<li>test2.insert_one(data)  插入一条文档</li>
<li>test2.insert_many(data-list) 插入多条文档</li>
<li>test2.update_one({‘x’:1},{‘$set’:{‘x’:3}},upsert=True)一般会在防止重复性的数据被存放到数据库内要用的</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/08/爬虫之Mongodb常用命令/" data-id="cjtyh7xj20072gkwvrrmcdih6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-富文本、分页" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/03/富文本、分页/" class="article-date">
  <time datetime="2018-04-03T00:05:22.000Z" itemprop="datePublished">2018-04-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/03/富文本、分页/">富文本、分页</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>富文本、分页</h5><p></p>
<hr>
<hr>
<p></p><h6>富文本</h6><p></p>
<ul>
<li>1.下载链接:  <a href="http://ueditor.baidu.com/website/download.html#ueditor,目前最新版本是ueditor-1.4.3.3" target="_blank" rel="noopener">http://ueditor.baidu.com/website/download.html#ueditor,目前最新版本是ueditor-1.4.3.3</a></li>
<li>2.将下载的文件全部存放在我们的django项目里面，路径为static/ueditor/下</li>
<li>3.将uecontroller.py文件放在与项目同名的文件夹下，该文件为格式文本请求地址，请求资源；需要将其中的依据引用代码稍做修改<code>import pyblog.settings as settings</code>，即引入项目的设置</li>
<li><p>4.在于项目同名的文件夹下的urls.py中设置路由</p>
<pre><code>from .uecontroller import handler
urlpatterns = [
    path(&apos;uecontroller&apos;,handler),
]
</code></pre></li>
<li><p>5.将ueditor/jsp/config.json文件复制到项目根目录下</p>
</li>
<li><p>6.将文件ueditor/_example/submitFormDemo.html中的部分script内容复制到前端页面fabu.html中，并且修改路径，其中博客页面中的内容标签需要加id，serverUrl</p>
<pre><code>&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;欢迎发布博客&lt;/title&gt;
    &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/static/ueditor/ueditor.config.js&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/static/ueditor/_examples/editor_api.js&quot;&gt;&lt;/script&gt;
    &lt;style type=&quot;text/css&quot;&gt;
        body{
            font-size:14px;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h2&gt;欢迎{{ user.username }}发布博客...&lt;/h2&gt;
    &lt;span style=&quot;color:red&quot;&gt;{{ msg }}&lt;/span&gt;
    &lt;form action=&quot;/pyblogA/fabu&quot; method=&quot;post&quot;&gt;
        {% csrf_token %}
        &lt;p&gt;标题：&lt;input type=&quot;text&quot; name=&apos;title&apos; style=&quot;width:500px&quot;&gt;&lt;/p&gt;
        &lt;p&gt;内容：&lt;textarea  id=&quot;myEditor&quot; name=&apos;context&apos; style=&quot;width:600px;height:400px&quot;&gt;&lt;/textarea&gt;&lt;/p&gt;
        &lt;input type=&quot;submit&quot; value=&quot;确认发布&quot;&gt;
    &lt;/form&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
        var editor_a = UE.getEditor(&apos;myEditor&apos;,{initialFrameHeight:300,serverUrl:&apos;/uecontroller&apos;});
    &lt;/script&gt;
&lt;/body&gt;
</code></pre></li>
<li><p>7.打开文件ueditor/_examples/editor_api.js，将baseURL的路径改为当前_src的路径，即<code>baseURL = &#39;/static/ueditor/_src/&#39;;</code></p>
</li>
<li><p>8.新建上传文件存储路径为static/upload/imgs/，并修改uecontroller.py中的代码</p>
<pre><code>try:
    #重新定义上传图片的名字
    truelyName = buildFileName(filename)
    webUrl = config.SavePath+ truelyName
    print(webUrl)
    #!!!!!!!!!!!!
    savePath =R&apos;static/upload/imgs/&apos;+webUrl
    # savePath =ROOT+webUrl
    print(&apos;savePath&apos;,savePath)
    f = codecs.open(savePath,&quot;wb+&quot;)
    for chunk in buf.chunks():
        f.write(chunk)
    f.flush()
    f.close()
    result.state = &quot;SUCCESS&quot;
    #返回富文本显示的图片路径
    result.url =&apos;/static/upload/imgs/&apos;+truelyName# truelyName
    print(&apos;truelyName&apos;, truelyName)
    result.title = truelyName
    result.original = truelyName
    response = HttpResponse(buildJsonResult(result))
    response[&quot;Content-Type&quot;] = &quot;text/plain&quot;
    return response
</code></pre></li>
</ul>
<p></p><h6>在登录成功欢迎页面显示博客列表，并链接进入博客页面</h6><p></p>
<ul>
<li><p>1.在发布博客的views.py中写入getAll函数</p>
<pre><code>def getAll():
    Blogset=Blog.objects.values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;BlogUser__username&apos;).all()
    return Blogset
</code></pre></li>
<li><p>2.在用户的views.py中</p>
<pre><code>from pyblogA.views import getAll
def welcome(request):
    Blogset=getAll()
    return render(request, &apos;welcome.html&apos;,
                  {&apos;user&apos;: request.session.get(&apos;user&apos;, None),
                   &apos;Blogset&apos;:Blogset
                   })
</code></pre></li>
<li><p>3.在登录欢迎页面welcome.html页面</p>
<pre><code>{% for foo in Blogset %}
		        <li>{{ foo.id }}&nbsp;&nbsp;
		            <a href="/pyblogA/showOne?id={{ foo.id }}">{{ foo.title }}</a>&nbsp;&nbsp;
		            {{ foo.createDate|date:'Y-m-d H:i:s' }}&nbsp;&nbsp;{{ foo.BlogUser__username }}
		        </li>
		{% endfor %}
</code></pre></li>
<li><p>4.接下来是链接进入博客页面，设置博客显示页面b.html</p>
<pre><code>&lt;body&gt;
    登录用户/非登录用户都可见
    &lt;!--某个文档的显示页面--&gt;
    &lt;h2&gt;标题：{{ blog.title }}&lt;/h2&gt;
    &lt;h3&gt;发布时间：{{ blog.createDate|date:'Y-m-d H:i:s' }}&lt;/h3&gt;
    &lt;h3&gt;作者：{{ blog.BlogUser__username }}&lt;/h3&gt;
    &lt;h2&gt;内容：&lt;/h2&gt;
    &lt;div style=&quot;width:85%;margin:0 auto&quot;&gt;
        {% autoescape off %}  #转义，否则显示编码
		            {{ blog.context }}
		        {% endautoescape %}
    &lt;/div&gt;
&lt;/body&gt;
</code></pre></li>
<li><p>5.在发布博客的urls中设置路径</p>
<pre><code>urlpatterns = [
    path(&apos;showOne&apos;,showOne),
]
</code></pre></li>
<li><p>6.在发布博客的views中定义showOne函数</p>
<pre><code>def showOne(request):
    id=request.GET.get(&apos;id&apos;,None)
    if id is None:
        return render(request,&apos;welcome.html&apos;)
    else:
        blog=Blog.objects.\
            values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;context&apos;,&apos;BlogUser__username&apos;).\
            filter(pk=id).all()
        return render(request,&apos;b.html&apos;,{&apos;blog&apos;:blog.first()})
</code></pre></li>
</ul>
<p></p><h6>分页</h6><p></p>
<ul>
<li><p>1.设置发布博客的views中的getAll函数</p>
<pre><code>from django.core.paginator import Paginator
def getAll(num):
    Blogset=Blog.objects.values(&apos;id&apos;,&apos;title&apos;,&apos;createDate&apos;,&apos;BlogUser__username&apos;).all()
    paginator = Paginator(Blogset,5)  # 创建分页器
    page=paginator.get_page(num)
    return page,paginator
</code></pre></li>
<li><p>2.在用户的views.py中</p>
<pre><code>def welcome(request):
    num=request.GET.get(&apos;num&apos;,1)
    Blogset=getAll(num)[0]
    paginator=getAll(num)[1]
    return render(request, &apos;welcome.html&apos;,
                  {&apos;user&apos;: request.session.get(&apos;user&apos;, None),
                   &apos;Blogset&apos;:Blogset,
                   &apos;paginator&apos;:paginator
                   })
</code></pre></li>
<li><p>3.在登录欢迎页面welcome.html页面中</p>
<pre><code>&lt;body&gt;
    {% if Blogset.has_previous %}
		        <a href="?num=1">首页</a>
		        <a href="?num={{ Blogset.previouse_page_number }}">上一页</a>
		    {% endif %}
    {% if Blogset.has_next %}
		        <a href="?num={{ Blogset.next_page_number }}">下一页</a>
		        <a href="?num={{ paginator.num_pages }}">尾页</a>
		    {% endif %}
&lt;/body&gt;
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/03/富文本、分页/" data-id="cjtyh7xhp006agkwv5kk932bl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy选择器css、xpath" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/scrapy选择器css、xpath/" class="article-date">
  <time datetime="2018-04-02T13:33:47.000Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/scrapy选择器css、xpath/">scrapy选择器css、xpath</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy选择器css、xpath</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>Scrapy自带了提取数据的机制。它们称为选择器，因为它们“选择”由XPath或CSS表达式指定的HTML文档的某些部分</li>
<li>XPath是用于选择XML文档中的节点的语言，其也可以与HTML一起使用</li>
<li>CSS是一种用于将样式应用于HTML文档的语言。它定义了选择器以将这些样式与特定的HTML元素相关联</li>
<li>Scrapy选择器构建在lxml库之上，这意味着它们的速度和解析精度非常相似</li>
</ul>
<p></p><h6>使用选择器</h6><p></p>
<ul>
<li><p>为了解释如何使用选择器，我们将使用Scrapy shell（提供交互式测试）和位于Scrapy文档服务器中的示例页面：<a href="http://doc.scrapy.org/en/latest/_static/selectors-sample1.html" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest/_static/selectors-sample1.html</a></p>
<pre><code>#打开shell
scrapy shell http://doc.scrapy.org/en/latest/_static/selectors-sample1.html 
#使用XPath和CSS选择标题标签中的文本:
response.xpath(&apos;//title/text()&apos;)
&gt;&gt;&gt;[&lt;Selector xpath=&apos;//title/text()&apos; data=&apos;Example website&apos;&gt;]
response.css(&apos;title::text&apos;)
&gt;&gt;&gt;[&lt;Selector xpath=&apos;descendant-or-self::title/text()&apos; data=&apos;Example website&apos;&gt;]
#.css()方法返回一个 SelectorList实例，它是新的选择列表。此API可用于快速选择嵌套数据：
response.css(&apos;img&apos;).xpath(&apos;@src&apos;).extract()
#要实际提取文本数据，必须调用选择器.extract() 方法,如果只想提取第一个匹配的元素，可以调用选择器 .extract_first()
response.xpath(&apos;//title/text()&apos;).extract()
response.xpath(&apos;//div[@id=&quot;images&quot;]/a/text()&apos;).extract_first()
#可以提供默认返回值作为参数
response.xpath(&apos;//div[@id=&quot;not-exists&quot;]/text()&apos;).extract_first(default=&apos;not-found&apos;)
</code></pre></li>
<li><p>Xpath选择器常用方法</p>
<pre><code>nodeName    选取此节点的所有节点
/           从根节点选取
//          从匹配选择的当前节点选择文档中的节点，不考虑它们的位置
.           选择当前节点
..          选取当前节点的父节点
@           选取属性
*           匹配任何元素节点
@*          匹配任何属性节点
Node()      匹配任何类型的节点
</code></pre></li>
<li><p>CSS选择器常用方法</p>
<pre><code>.class              .color              选择class=”color”的所有元素
#id                 #info               选择id=”info”的所有元素
*                   *                   选择所有元素
element             p                   选择所有的p元素
element,element     div,p               选择所有div元素和所有p元素
element element     div p               选择div标签内部的所有p元素
[attribute]         [target]            选择带有targe属性的所有元素
[arrtibute=value]   [target=_blank]     选择target=”_blank”的所有元素
</code></pre></li>
<li><p>获取基本URL和一些图像链接</p>
<pre><code>response.xpath(&apos;//base/@href&apos;).extract()
response.css(&apos;base::attr(href)&apos;).extract()

response.xpath(&apos;//a[contains(@href, &quot;image&quot;)]/@href&apos;).extract()
response.css(&apos;a[href*=&quot;image&quot;]::attr(href)&apos;).extract()
#其中a[href*=&quot;image&quot;]表示href的属性值包含“image”的所有a元素

response.xpath(&apos;//a[contains(@href, &quot;image&quot;)]/img/@src&apos;).extract()
response.css(&apos;a[href*=image] img::attr(src)&apos;).extract()
</code></pre></li>
</ul>
<h3 id="参考大神佳作Scrapy爬虫入门教程五-Selectors（选择器）"><a href="#参考大神佳作Scrapy爬虫入门教程五-Selectors（选择器）" class="headerlink" title="参考大神佳作Scrapy爬虫入门教程五 Selectors（选择器）"></a>参考大神佳作<a href="https://blog.csdn.net/Inke88/article/details/60589170" target="_blank" rel="noopener">Scrapy爬虫入门教程五 Selectors（选择器）</a></h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/scrapy选择器css、xpath/" data-id="cjtyh7xf3004ogkwv1vlrfkw4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy命令行详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/02/scrapy命令行详解/" class="article-date">
  <time datetime="2018-04-02T11:08:41.000Z" itemprop="datePublished">2018-04-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/02/scrapy命令行详解/">scrapy命令行详解</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy命令行详解</h5><p></p>
<hr>
<hr>
<ul>
<li><p>创建项目<code>scrapy startproject 项目名</code></p>
<pre><code>#测试网站：http://quotes.toscrape.com/
scrapy startproject quotetutorial
</code></pre></li>
<li><p>创建爬虫<code>scrapy genspider spider文件名 网站域名</code></p>
<pre><code>cd quotetutorial         进入项目
scrapy genspider quotes quotes.toscrape.com   创建爬虫
</code></pre></li>
<li><p>运行爬虫<code>scrapy crawl 爬虫文件名</code></p>
<pre><code>scrapy crawl quotes
scrapy crawl quotes -o quotes.json   保存爬取数据为json格式,还有其他格式如.jl、.csv、.xml、.pickle、.marshal等等
</code></pre></li>
<li><p>在项目中常用的其他命令（局部命令）</p>
<pre><code>scrapy check   检查spider文件有无语法错误
scrapy list    列出spider路径下的spider文件
scrapy bench   测试电脑当前爬取速度性能，即基准测试
</code></pre></li>
</ul>
<ul>
<li><p>全局命令</p>
<pre><code>scrapy fetch &lt;url&gt;  将网页内容下载下来，然后在终端打印当前返回的内容
scrapy view &lt;url&gt;   将网页内容保存下来，并在浏览器中打开当前网页内容，直观呈现要爬取网页的内容（发现这个与上述命令效果一样啊）
scrapy shell [url]  打开 scrapy 显示台，进入命令行交互模式
可以用来做测试,（exit()退出模式）
scrapy version [-v]  显示scrapy版本，后面加 -v 可以显示scrapy依赖库的版本
scrapy runspider &lt;spider_file.py&gt;  运行一个自包含在Python文件中的爬虫，而不必创建一个项目
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/02/scrapy命令行详解/" data-id="cjtyh7xeu004kgkwvoknqrpwx" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-发布及文件上传" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/01/发布及文件上传/" class="article-date">
  <time datetime="2018-04-01T09:47:40.000Z" itemprop="datePublished">2018-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/01/发布及文件上传/">发布及文件上传</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>发布及文件上传</h5><p></p>
<hr>
<hr>
<p></p><h6>发布博客</h6><p></p>
<ul>
<li><p>用户登录之后，点击“发布博客”即可进入发布博客页面，在这儿需要在登录的欢迎页面增加一下这个发布博客链接</p>
<pre><code>&lt;a href=&quot;/pyblogA/fabu&quot;&gt;发布博客&lt;a/&gt;
</code></pre></li>
<li><p>之后编辑发布博客的前端页面</p>
<pre><code>&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;欢迎发布博客&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h2&gt;欢迎{{ user.username }}发布博客...&lt;/h2&gt;
    &lt;span style=&quot;color:red&quot;&gt;{{ msg }}&lt;/span&gt;
    &lt;form action=&quot;/pyblogA/fabu&quot; method=&quot;post&quot;&gt;
        {% csrf_token %}
        &lt;p&gt;标题：&lt;input type=&quot;text&quot; name=&apos;title&apos; style=&quot;width:300px&quot;&gt;&lt;/p&gt;
        &lt;p&gt;内容：&lt;textarea  name=&apos;context&apos; style=&quot;width:300px;height:200px&quot;&gt;&lt;/textarea&gt;&lt;/p&gt;
        &lt;input type=&quot;submit&quot; value=&quot;确认发布&quot;&gt;
    &lt;/form&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre></li>
<li><p>在该app的models中编辑与数据库的映射</p>
<pre><code>from django.db import models
from bloguser.models import BlogUser
class Blog(models.Model):
    title=models.CharField(max_length=30,null=True)
    context=models.CharField(max_length=500,null=True)
    createDate=models.DateTimeField(null=True)    #默认当前时间
    BlogUser=models.ForeignKey(&apos;bloguser.BlogUser&apos;,on_delete=None)   #app下的名字
</code></pre></li>
<li><p>需要在项目的settings.py下设置路径</p>
<pre><code>urlpatterns = [
    path(&apos;pyblogA/&apos;,include(&apos;pyblogA.urls&apos;)),
]
</code></pre></li>
<li><p>接着在该app的urls下设置路径</p>
<pre><code>urlpatterns = [
    path(&apos;fabu&apos;, fabu),
]
</code></pre></li>
<li><p>接下来编辑该appviews内容</p>
<pre><code>from django.shortcuts import render,redirect,reverse
from .models import *
from django.http import HttpResponse
import time,datetime,os

def fabu(request):
    user = request.session.get(&apos;user&apos;, None)
    if request.method==&apos;GET&apos;:
        if user is not None:
            return render(request,&apos;fabu.html&apos;,{&apos;user&apos;: request.session.get(&apos;user&apos;, None)})
        else:
            return render(request,&apos;login.html&apos;)
    elif request.method==&apos;POST&apos;:
        blogA=Blog()
        blogA.title=request.POST.get(&apos;title&apos;)
        blogA.context=request.POST.get(&apos;context&apos;)
        blogA.createDate=datetime.datetime.now()

        uid=request.session.get(&apos;user&apos;)[&apos;id&apos;]
        bloguserset=BlogUser.objects.filter(pk=uid).all()
        blogA.BlogUser=bloguserset.first()

        blogA.save()
        ret={&apos;msg&apos;:&apos;发布成功！&apos;,&apos;user&apos;:request.session.get(&apos;user&apos;)}
        return render(request,&apos;fabu.html&apos;,ret)
</code></pre></li>
</ul>
<p></p><h6>文件上传</h6><p></p>
<ul>
<li><p>创建一个html文件用于上传文件</p>
<pre><code>&lt;form method=&quot;post&quot; action=&quot;/pyblogA/upload&quot; enctype=&quot;multipart/form-data&quot;&gt;
    {% csrf_token %}
    选择文件：&lt;input type=&quot;file&quot; name=&quot;myfile&quot;&gt;
    &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt;
&lt;/form&gt;
</code></pre></li>
<li><p>在该app下设置路径</p>
<pre><code>urlpatterns = [
    path(&apos;upload&apos;, upload),
]
</code></pre></li>
<li><p>在该app的views中编辑业务逻辑</p>
<pre><code>def upload(request):
    myfile=request._files.get(&apos;myfile&apos;)  #获取上传的文件
    file_path=os.path.join(&apos;file&apos;,myfile.name)  #配置存放路径为file
    file=open(file_path,&apos;wb+&apos;)           #打开并写入
    for row in myfile.chunks():      #循环chunks(),里面包含用户上传的文件
        file.write(row)              #写入到我们创建的那个文件中
    file.close()
    return HttpResponse(&apos;上传成功！&apos;)
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/01/发布及文件上传/" data-id="cjtyh7xgj005kgkwv3m7vmksu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Django学习/">Django学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-HTTP报文" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/01/HTTP报文/" class="article-date">
  <time datetime="2018-04-01T03:15:03.000Z" itemprop="datePublished">2018-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/01/HTTP报文/">HTTP报文</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>HTTP报文</h5><p></p>
<hr>
<hr>
<p></p><h6>定义</h6><p></p>
<ul>
<li>用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的<br>HTTP 报文叫做请求报文，响应端（服务器端）的叫做响应报文。<br>HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文<br>本</li>
<li><p>一个HTTP报文由3部分组成，分别是:起始行（start line）、首部（header）、主体（body），样子就像这个：</p>
<pre><code>#请求报文的格式：                       #响应报文的格式：
&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;       &lt;version&gt; &lt;status&gt;&lt;reason-phrase&gt;
&lt;headers&gt;                              &lt;headers&gt;

&lt;entity-body&gt;                          &lt;entity-body&gt;
</code></pre></li>
<li><p>格式内容概略</p>
<pre><code>##method
方法　　　　　　　　    描述　　　　　　　　      是否包含主体
GET 　　　　从服务器获取一份文档 　　　　　　　　 　   否
HEAD 　　　只从服务器获取文档的首部 　　　　　　  　　　否
POST 　　   向服务器发送需要处理的数据　　　　　　　　　是
PUT 　　　　将请求的主体部分存储在服务器上 　　　  　　 是
TRACE 　　 对可能经过代理服务器传送到服务器上去的报文进行跟踪 　　否
OPTIONS 　 决定可以在服务器上执行哪些方法 　　　　　　  否
DELETE 　　从服务器上删除一份文档 　　　　　　　　　　  否   

##request-URL   
命名了所有请求资源，或者URL路径组件的完整URL，
一个完整的包括类型、主机名和可选路径名的统一资源引用名，
如：http://www.example.com/path/to/file.html

##version
报文所使用的HTTP版本，其格式如：HTTP/&lt;major&gt;.&lt;minor&gt;
其中主要版本号(major)和次要版本号(minor)都是整数，如：HTTP/1.1

##status、reason-phrase
状态码                类别                原因短语
1XX Informational（信息性状态码）     接收的请求正在处理
2XX Success        （成功状态码）         请求正常处理完毕
3XX Redirection（重定向状态码）          需要进行附加操作以完成请求
4XX Client Error（客户端错误状态码）  服务器无法处理请求
5XX Server Error（服务器错误状态码）  服务器处理请求出错

##headers
可以有0个或多个首部，每个首部都包含一个名字，后面跟着一个冒号(:)，然后是一个可选的空格，接着是一个值，最后是一个CRLF

##entity-body
实体的主体部分包含一个由任意数据组成的数据块。并不是所有的报文都包含实体的主体部分。如GET请求就不包含实体
</code></pre></li>
</ul>
<p></p><h6>headers-首部分类</h6><p></p>
<ul>
<li><p>通用首部</p>
<ul>
<li>既可以出现在请求报文中，也可以出现在响应报文中</li>
<li><p>通用的信息性首部：</p>
<pre><code>    首部 　　　　　　　　　　        描述
Connection 　　　　　　  允许客户端和服务器指定与请求/响应连接有关的选项
Date 　　　　　　　　　   提供日期和时间标志，说明报文是什么时间创建的
MIME-Version 　　　　　  给出了发送端使用的MIME版本
Trailer 　　　　　　　　　如果报文采用了分块传输编码(chunked transfer encoding)方式，就可以用这个首部列出位于报文拖鞋 (trailer)部分的首部集合。
Transfer-Encoding 　　  告知接收端为了保证报文的可靠传输，对报文采用了什么编码方式。
Update 　　　　　　　　   给出了发送端可能想要&quot;升级&quot;使用的新版本或协议
Via 　　　　　　　　　　   显示了报文经过的中间节点(代理、网关)
</code></pre></li>
<li><p>通用缓存首部：</p>
<pre><code>    首部 　　　　　　　　　　描述
Cache-Control 　　　　  用于随报文传送缓存指示
Pragma 　　　　　　　　  另一种随报文传送指示的方式，但并不专用于缓存
</code></pre></li>
</ul>
</li>
<li><p>请求首部</p>
<ul>
<li>请求首部是在请求报文中有意义的首部。用于说明是谁或什么在发送请求，请求源自何处，或者客户端的喜好及能力。服务器可以根据请求首部给出的客户端的信息，试着为客户端提供更好的响应</li>
<li><p>请求的信息性首部：</p>
<pre><code>    首部 　　　　　　　　　　　　 描述
Client-IP 　　　　　　　　　提供了运行客户端的机器的IP地址
From 　　　　　　　　　　　 提供了客户端用户的E-mail地址
Host 　　　　　　　　　　　 给出了接收请求的服务器的主机名和端口号
Referer 　　　　　　　　　　提供了包含当前请求URI的文档的URL
UA-Color 　　　　　　　　　 提供了与客户端显示器的显示颜色有关的信息
UA-CPU 　　　　　　　　　　 给出了客户端CPU的类型或制造商
US-Disp 　　　　　　　　　　提供了与客户端显示器(屏幕)能力有关的信息
US-OS 　　　　　　　　　　  给出了客户端显示器的像素信息
UA-Pixels 　　　　　　　　　提供了客户端显示器的像素信息
User-Agent 　　　　　　　　 将发起请求的应用程序名称告知服务器(User-Agent)用户代理，其实不就是浏览器吗
</code></pre></li>
<li><p>Accept首部<br>Accept首部为客户端提供了一种将其喜好和能力告知服务器的方式，包括他们想要什么，可以使用什么，以及最重要的，他们不想要什么。这样服务器就可以根据这些额外信息，对要发送的内容做出更明智的决定。Accept首部会使连接的两端都受益。客户端会得到他们想要的内容，服务器则不会浪费其时间和带宽来发送客户端无法使用的东西</p>
<pre><code>    首部 　　　　　　　　　　 描述
Accept 　　　　　　　　   告诉服务器能够发送哪些媒体类型
Accept-Charset 　　　　  告诉服务器能够发送哪些字符集
Accept-Encoding 　　　　 告诉服务器能够发送哪些编码方式
Accept-Language 　　　   告诉服务器能够发送哪些语言
TE 　　　　　　　　　　　  告诉服务器可以使用哪些扩展传输编码
</code></pre></li>
<li><p>条件请求首部<br>有时客户端希望为请求加上某些限制。比如客户端已经有了一份副本，就希望只在服务器上的文档与客户端拥有的副本有所区别时，才请求服务器传输文档。通过条件请求首部，客户端就可以加上这种限制，要求服务器在对请求进行相应之前，确保某个请求为真</p>
<pre><code>    首部 　　　　　　　　　　 描述
Expect 　　　　　　　　  允许客户端列出某请求所要求的服务器行为
If-Match 　　　　　　　　如果实体标记与文档当前的实体标记相匹配，就或者这份文档
If-Modified-Since 　　　除非在某个指定的日期之后资源被修改过，否则就限制这个请求
If-Range 　　　　　　　　允许对文档的某个范围进行条件请求
If-Unmodified-Since 　　除非在某个指定的日期之后资源没有被修改过，否则就限制这个请求
Range 　　　　　　　　　 如果服务器支持范围请求，就请求资源的指定范围
</code></pre></li>
<li><p>安全请求首部<br>HTTP本身就支持一种简单的机制，可以对请求进行质询/响应认证。这种机制要求客户端在获取特定的资源之前，先对自身进行认证，这样就可以使事务稍微安全一些</p>
<pre><code>    首部 　　　　　　　　　　 描述
Authorization 　　　　　 包含了客户端提供给服务器，以便对其自身进行认证的数据
Cookie 　　　　　　　　　 客户端用它想服务器传送一个令牌-他并不是真正的安全首部，但却是隐含了安全功能
Cookie2 　　　　　　　　  用来说明请求端支持的cookie版本
</code></pre></li>
<li><p>代理请求首部<br>随着因特网上代理的普遍应用，人们定义了几个首部来协助其更好地工作</p>
<pre><code>    首部 　　　　　　　　　　 描述
Max-Forword 　　　　　   在通往源端服务器的路径上，将请求转发给其他代理或网关的最大次数-与TRACE方法一同使用
Proxy-Authorization 　　与Authorization首部相同，但这个首部是在与代理进行认证时使用的
Proxy-Connection 　　　 与Connection首部相同，但这个首部是在于代理建立连接时使用的
</code></pre></li>
</ul>
</li>
<li><p>响应首部</p>
<ul>
<li>响应首部为客户端提供了一些额外的信息，比如谁在发送响应、响应者的功能，甚至与响应相关的一些特殊指令。这些首部有助于客户端处理响应，并在将来发起更好的请求</li>
<li><p>响应的信息性首部：</p>
<pre><code>首部 　　　　　　　　     描述
Age 　　　　　　　　 (从最初创建开始)响应持续时间
Public 　　　　　　　服务器为其资源支持的请求方法列表
Retry-After 　　　　如果资源不可用的话，再次日期或时间重试
Server 　　　　　　　服务器应用程序软件的名称和版本
Title 　　　　　　　 对HTML文档来说，就是HTML文档的源端给出的标题
Warning 　　　　　　 比原因短语中更详细的一些警告报文
</code></pre></li>
<li><p>协商首部<br>如果资源有多种表示方法-比如，如果服务器上有某文档的法语和德语译稿，HTTP/1.1可以为服务器和客户端提供对资源进行协商的能力</p>
<pre><code>首部　　　　　　　　         描述
Accept-Ranges 　　 对此资源来说，服务器可接受的范围类型
Vary 　　　　　　　  服务器查看的其他首部的列表，可能会使响应发生变化；
                   也就是说，这是一个首部列表，服务器会根据这些首部的内容挑选出最合适的资源版本　　　　　　　　　　　 发送给客户端
</code></pre></li>
<li><p>安全响应首部</p>
<pre><code>      首部                              描述
Proxy-Authenticate             来自代理的对客户端的质询列表
Set-Cookie                     不是真正的安全首部，但隐含有安全功能；可以在客户端设置一个令牌，以便服务器对客户端进行标识。
Set-Cookie2                 与Set-Cookie类似。
WWW-Authenticate             来自服务器的对客户端的质询列表
</code></pre></li>
</ul>
</li>
<li><p>实体首部</p>
<ul>
<li>描述主体的长度和内容，或者资源自身</li>
<li>由于请求和响应文本中都可能包含实体部分，所以在这两种类型的报文中都可能出现这些首部。实体首部提供了有关实体及其内容的大量信息，从有关对象类型的信息，到能够对资源使用的各种有效的请求方法。总之，实体首部可以告知报文的接收者它在对什么进行处理</li>
<li><p>实体信息性首部:</p>
<pre><code>首部 　　　　　　　        描述
Allow 　　　　　　  列出了可以对此实体执行的请求方法
Location 　　　　  告知客户端实体实际上位于何处；用于将接收端定向到资源的位置上去
</code></pre></li>
<li><p>内容首部<br>内容首部提供了与实体内容有关的特定信息，说明了其类型、尺寸以及处理它所需的其他有用信息。比如，Web浏览器可以通过查看返回的内容类型，得知如何显示对象</p>
<pre><code>    首部 　　　　　　　　　　　  描述
Content-Base 　　　　　　   解析主体中的相对URL时使用的基础URL
Content-Encoding 　　　　  对主体执行的任意编码方式
Content-Language 　　　　  理解主体时最适宜使用的自然语言
Content-Length 　　　　　  主体的长度或尺寸
Content-Location 　　　　　资源实际所处的位置
Content-MD5 　　　　　　　 主体的MD5校验
Content-Range 　　　　　　 在整个资源中此实体表示的字节范围
Content-Type 　　　　　　  这个主体的对象模型
</code></pre></li>
<li><p>实体缓存首部<br>通用的缓存首部说明了如何或什么时候进行缓存。实体的缓存首部提供了与被缓存实体有关的信息，比如验证已缓存的资源副本是否仍然有效所需的信息，以及更好地估计已缓存资源合适失效所需的线索</p>
<pre><code>首部 　　　　　　         描述
ETag 　　　　　   与此实体有关的实体标记
Expires 　　　　  实体不在有效，要从原始的源端再次获取此实体的日期和时间
Last-Modified 　 这个实体最后一次被修改的日期和时间
</code></pre></li>
</ul>
</li>
<li><p>以上参考大神佳作<a href="https://blog.csdn.net/lmj1436140682/article/details/63262459" target="_blank" rel="noopener">HTTP 报文及作用</a>，参考大神佳作<a href="https://blog.csdn.net/wzx19840423/article/details/47811559" target="_blank" rel="noopener">HTTP报文详解</a></p>
</li>
</ul>
<p></p><h6>实体部分</h6><p></p>
<ul>
<li>实体的主体是HTTP报文的负荷,就是HTTP要传输的内容</li>
<li>HTTP报文可以承载很多类型的数字数据，图片、视频、HTML文档、软件应用程序、信用卡事务、电子邮件等</li>
<li>参考大神佳作<a href="https://blog.csdn.net/u012422829/article/details/51570652" target="_blank" rel="noopener">报文实体和编码</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/01/HTTP报文/" data-id="cjtyh7x8e0013gkwv0me7rgcc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/网络基础知识/">网络基础知识</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy基础了解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/29/scrapy基础了解/" class="article-date">
  <time datetime="2018-03-29T01:25:36.000Z" itemprop="datePublished">2018-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/29/scrapy基础了解/">scrapy基础了解</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>scrapy基础了解</h5><p></p>
<hr>
<hr>
<p></p><h6>简介</h6><p></p>
<ul>
<li>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中</li>
<li>依赖包<ul>
<li>1.wheel      安装该文件后就可以安装.whl的依赖文件</li>
<li>2.lxml       解析页面 </li>
<li>3.PyOpenssl</li>
<li>4.Twisted</li>
<li>5.Pywin32，pypiwin32</li>
<li>6.Scrapy </li>
</ul>
</li>
<li>基本思路:<img src="../scrapy.jpg" alt="Scrapy基本思路"><ul>
<li>1.Scrapy Engine: 引擎，负责Spiders、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等等！</li>
<li>2.Scheduler(调度器): 它负责接受引擎发送过来的requests请求，并按照一定的方式进行整理排列，入队、并等待Scrapy Engine(引擎)来请求时，交给引擎</li>
<li>3.Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spiders来处理</li>
<li>4.Spiders：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)</li>
<li>5.Item Pipeline：它负责处理Spiders中获取到的Item，并进行处理，比如去重，持久化存储（存数据库，写入文件，总之就是保存数据用的）</li>
</ul>
</li>
<li>测试网站：<a href="http://quotes.toscrape.com/" target="_blank" rel="noopener">http://quotes.toscrape.com/</a></li>
</ul>
<p></p><h6>详解</h6><p></p>
<ul>
<li><p>1.进入要放置项目的目录，shift+右键的shell，输入命令：<code>scrapy startproject quotetutorial</code>，创建项目</p>
<ul>
<li>spiders    #这个目录放置爬虫</li>
<li>items.py   #这个文件定义我们需要获取的字段</li>
<li>pipelines.py    #这个文件用来定义数据存储</li>
<li>settings.py        #这个文件用来设置</li>
</ul>
</li>
<li><p>2.进入项目，<code>cd quotetutorial</code>,创建爬虫：<code>scrapy genspider quotes quotes.toscrape.com</code> </p>
</li>
<li><p>3.在spiders文件夹下的quotes中编写自己的爬虫</p>
<pre><code>import scrapy
from quotetutorial.items import QuoteItem
class QuotesSpider(scrapy.Spider):
    name = &apos;quotes&apos;
    allowed_domains = [&apos;quotes.toscrape.com&apos;]
    start_urls = [&apos;http://quotes.toscrape.com/&apos;]

    def parse(self, response):
        quotes=response.css(&apos;.quote&apos;)
        for quote in quotes:
            item=QuoteItem() #先声明一个对象，然后赋值
            text=quote.css(&apos;.text::text&apos;).extract_first()
            author=quote.css(&apos;.author::text&apos;).extract_first()
            tags=quote.css(&apos;.tags .tag::text&apos;).extract()
            item[&apos;text&apos;]=text
            item[&apos;author&apos;]=author
            item[&apos;tags&apos;]=tags
            yield item #做下一步的存储操作
        next=response.css(&apos;.pager .next a::attr(href)&apos;).extract_first()
        url=response.urljoin(next)
        yield scrapy.Request(url=url,callback=self.parse)
</code></pre></li>
<li><p>4.在items.py文件中定义一些字段，这些字段用来临时存储需要保存的数据。方便后面保存数据到其他地方，比如数据库或者本地文本之类的</p>
<pre><code>import scrapy
class QuoteItem(scrapy.Item):
    text=scrapy.Field()
    author=scrapy.Field()
    tags=scrapy.Field()
</code></pre></li>
<li><p>5.在Terminal中运行爬虫<code>scrapy crawl quotes</code>;运行并且保存爬取数据为json格式<code>scrapy crawl quotes -o quotes.json</code> </p>
</li>
<li><p>6.保存数据到Mongodb中</p>
<ul>
<li><p>6.1在pipelines.py编写连接</p>
<pre><code>from scrapy.exceptions import DropItem
import pymongo
class TextPipeline(object):
    def __init__(self):
        self.limit=50
    def process_item(self, item, spider):
        if item[&apos;text&apos;]:
            if len(item[&apos;text&apos;])&gt;self.limit:
                item[&apos;text&apos;]=item[&apos;text&apos;][0:self.limit].rstrip()+&apos;...&apos;
            return item
        else:
            return DropItem(&apos;Missing Text&apos;)   #如果text不存在，则抛出异常
class MongoPipeline(object):
    def __init__(self,mongo_uri,mongo_db):
        self.mongo_uri=mongo_uri
        self.mongo_db=mongo_db
    @classmethod
    def from_crawler(cls,crawler):
        return cls(
            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),
            mongo_db=crawler.settings.get(&apos;MONGO_DB&apos;)
        )
    def open_spider(self,spider):
        self.client=pymongo.MongoClient(self.mongo_uri)
        self.db=self.client[self.mongo_db]
    def process_item(self,item,spider):
        name=item.__class__.__name__
        self.db[name].insert(dict(item))
        return item
    def close_spider(self,spider):
        self.client.close()  
</code></pre></li>
<li><p>6.2在settings中设置</p>
<pre><code>MONGO_URI=&apos;localhost:27017&apos;
MONGO_DB=&apos;quotetutorial&apos;

ITEM_PIPELINES = {
   &apos;quotetutorial.pipelines.TextPipeline&apos;: 300,
   &apos;quotetutorial.pipelines.MongoPipeline&apos;: 1000,
}
</code></pre></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/29/scrapy基础了解/" data-id="cjtyh7xez004mgkwvyel8ypxs" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫学习/">爬虫学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-网络配置、系统查看" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/28/网络配置、系统查看/" class="article-date">
  <time datetime="2018-03-28T15:00:41.000Z" itemprop="datePublished">2018-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/28/网络配置、系统查看/">网络配置、系统查看</a>
    </h1>
  


      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  
	  
        <p></p><h5>网络配置、系统查看</h5><p></p>
<hr>
<hr>
<p></p><h6>网络配置</h6><p></p>
<ul>
<li>VMware的三种网络连接方式区别</li>
<li>桥接模式<ul>
<li>在局域网内，虚拟机和宿主机视为两台PC机；可以单独通过局域网网关或者路由访问外网</li>
<li>利用相同的网关网段配置，Bridged可用来配置集群</li>
</ul>
</li>
<li>NAT（网络地址转换）<ul>
<li>NAT方式使虚拟机接入外网方便，不需要进行其他配置，只需要物理主机可以上网即可</li>
<li>NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，无法进行手工修改，因此虚拟系统也就无法和本局域网中的其他真实主机进行通讯</li>
<li>不能用NAT配置集群</li>
</ul>
</li>
<li>Host-Only（主机）<ul>
<li>这种模式下，所有局域网内所有虚拟机互通，但虚拟机无法访问外网，与外网完全隔离</li>
<li>此种模式同样可以配置集群，但是集群无法访问外网，比较适合公司内网</li>
</ul>
</li>
</ul>
<p></p><h6>linux系统ifconfig命令不显示IP地址或者只显示127.0.0.1</h6><p></p>
<ul>
<li>1.在Linux系统中输入命令:   vi  /etc/sysconfig/network-scripts/ifcfg-ens33</li>
<li>2.修改文件中的ONBOOT=no,将no改为yes</li>
<li>3.重启服务: service network restart</li>
</ul>
<p></p><h6>系统查看</h6><p></p>
<ul>
<li><p>查看进程</p>
<pre><code>ps -A 显示所有程序
ps -H 显示树状结构，表示程序间的相互关系
ps u 以用户为主的格式来显示程序状况
ps aux|less 查看所有运行中的进程
</code></pre></li>
<li><p>监控系统资源</p>
<pre><code>top 查看整个系统运行状况；该命令功能十分强大，但是它的缺点是会消耗很多系统资源
free -m 显示内存使用情况
</code></pre></li>
<li><p>查看硬盘占用</p>
<pre><code>df -h  检查linux服务器的文件系统的磁盘空间占用情况
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/28/网络配置、系统查看/" data-id="cjtyh7xje0078gkwv9bh0r6l3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux学习/">Linux学习</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/6/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django学习/">Django学习</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA项目部署/">JAVA项目部署</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux学习/">Linux学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB数据库/">MongoDB数据库</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL学习/">MySQL学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx学习/">Nginx学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python学习/">Python学习</a><span class="tag-list-count">27</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis数据库/">Redis数据库</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web前端/">Web前端</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全测试/">安全测试</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/性能测试/">性能测试</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫学习/">爬虫学习</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络基础知识/">网络基础知识</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自动化测试/">自动化测试</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件工具/">软件工具</a><span class="tag-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Django学习/" style="font-size: 12.22px;">Django学习</a> <a href="/tags/JAVA项目部署/" style="font-size: 13.33px;">JAVA项目部署</a> <a href="/tags/Linux学习/" style="font-size: 18.89px;">Linux学习</a> <a href="/tags/MongoDB数据库/" style="font-size: 12.22px;">MongoDB数据库</a> <a href="/tags/MySQL学习/" style="font-size: 18.89px;">MySQL学习</a> <a href="/tags/Nginx学习/" style="font-size: 10px;">Nginx学习</a> <a href="/tags/Python学习/" style="font-size: 20px;">Python学习</a> <a href="/tags/Redis数据库/" style="font-size: 15.56px;">Redis数据库</a> <a href="/tags/Web前端/" style="font-size: 16.67px;">Web前端</a> <a href="/tags/大数据/" style="font-size: 13.33px;">大数据</a> <a href="/tags/安全测试/" style="font-size: 11.11px;">安全测试</a> <a href="/tags/性能测试/" style="font-size: 15.56px;">性能测试</a> <a href="/tags/爬虫学习/" style="font-size: 17.78px;">爬虫学习</a> <a href="/tags/网络基础知识/" style="font-size: 10px;">网络基础知识</a> <a href="/tags/自动化测试/" style="font-size: 12.22px;">自动化测试</a> <a href="/tags/软件工具/" style="font-size: 14.44px;">软件工具</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">46</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">11</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/01/jenkins自动化部署-构建后台项目/">jenkins自动化部署--构建后台项目</a>
          </li>
        
          <li>
            <a href="/2019/03/25/MySQL数据库读写分离/">MySQL数据库读写分离</a>
          </li>
        
          <li>
            <a href="/2019/03/25/MySQL数据库主从复制/">MySQL数据库主从复制</a>
          </li>
        
          <li>
            <a href="/2019/03/24/清理内存缓存与交换空间/">清理内存缓存与交换空间</a>
          </li>
        
          <li>
            <a href="/2019/03/23/Nginx转发SSH代理-Stream模块/">Nginx转发SSH代理-Stream模块</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">About</h3>
    <div class="widget">
       Email:<a>liuyongqian51@163.com</a><br />
          QQ:<a>272501447</a><br />
	  Github:<a></a>
    </div>
  </div>

  
  

</aside>


        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 刘永前<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>

</footer>


    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>